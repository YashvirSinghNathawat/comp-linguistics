{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce75d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1934cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read File From chat_gpt\n",
    "with open('chat_gpt_output.txt', 'r',encoding = 'utf-8') as file:\n",
    "    # Read all lines from the file\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c8b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "chatgpt_sentence_list = [] \n",
    "chatgpt_ner_unfiltered_list = []\n",
    "\n",
    "i = 0\n",
    "length = len(lines)\n",
    "print(length)\n",
    "while i < length:\n",
    "    chatgpt_sentence_list.append(lines[i])\n",
    "    i+=1\n",
    "    chatgpt_ner_unfiltered_list.append(lines[i])\n",
    "    i+=2\n",
    "print(len(chatgpt_ner_unfiltered_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e88f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "# Refining ner_list\n",
    "chatgpt_ner_list = []\n",
    "for line in chatgpt_ner_unfiltered_list:\n",
    "    word_list = line.split(',')\n",
    "    ner_word_tags = []\n",
    "    for word in word_list:\n",
    "        ner_word_tags.append(word.split(':')[1].strip())\n",
    "    chatgpt_ner_list.append(ner_word_tags)\n",
    "print(len(chatgpt_ner_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a5157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Manual Dataset\n",
    "with open('manual_input.txt', 'r',encoding = 'utf-8') as file:\n",
    "    # Read all lines from the file\n",
    "    lines = file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ddf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_sentence_list = [] \n",
    "manual_ner_unfiltered_list = []\n",
    "\n",
    "i = 0\n",
    "length = len(lines)\n",
    "while i < length:\n",
    "    manual_sentence_list.append(lines[i])\n",
    "    i+=1\n",
    "    manual_ner_unfiltered_list.append(lines[i])\n",
    "    i+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3931d203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अब आर-पार की लड़ाई लड़ने का ऐलान करते हुए दूसरे विभागों के कर्मचारी भी समर्थन में आ गए हैं।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(manual_sentence_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd534ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "# Refining manual_ner_list\n",
    "manual_ner_list = []\n",
    "manual_ner_dict = []\n",
    "for line in manual_ner_unfiltered_list:\n",
    "    word_list = line.split(',')\n",
    "    ner_word_tags = []\n",
    "    ner_word_dict = {}\n",
    "    for word in word_list:\n",
    "        ner_word_tags.append(word.split(':')[1].strip())\n",
    "        ner_word_dict[word.split(':')[0].strip()] = word.split(':')[1].strip()\n",
    "    manual_ner_dict.append(ner_word_dict)\n",
    "    manual_ner_list.append(ner_word_tags)\n",
    "print(len(manual_ner_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "510e166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1038fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change String Tag to ID\n",
    "ner_number = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6 , 'B-MISC' : 7 , 'I-MISC' : 8}\n",
    "label_list = ner_number\n",
    "def change_ner_to_id(ner_list):\n",
    "    id_list = []\n",
    "    for tag in ner_list:\n",
    "        if tag.replace(\" \",\"\") in ner_number:\n",
    "            id_list.append(ner_number[tag.replace(\" \",\"\")])\n",
    "        else:\n",
    "            id_list.append(0)\n",
    "        \n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93aae05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFlattenList(nested_list):\n",
    "    flattened_list = [item for sublist in nested_list for item in sublist]\n",
    "    return flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7df1cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoreHelper(y_pred, y_true,positive_label = 1):\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db3afde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(true_list,predicted_list,curr_tag):\n",
    "    true_list_zero_one = []\n",
    "    for tag in true_list:\n",
    "        true_list_zero_one.append(1 if tag==curr_tag else 0)\n",
    "    predicted_list_zero_one = []\n",
    "    for tag in predicted_list:\n",
    "        predicted_list_zero_one.append(1 if tag==curr_tag else 0)\n",
    "    return getScoreHelper(predicted_list_zero_one,true_list_zero_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6f7d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(true_list,predicted_list):\n",
    "    # Flatten List\n",
    "    true_list_flatten = getFlattenList(true_list)\n",
    "    predicted_list_flatten = getFlattenList(predicted_list)\n",
    "    \n",
    "    #Change String Tag to ID\n",
    "    true_id_list = change_ner_to_id(true_list_flatten)\n",
    "    predicted_id_list = change_ner_to_id(predicted_list_flatten)\n",
    "    \n",
    "    precision_list = [] \n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    for i in range(0,9):\n",
    "        precision, recall, f1_score = getScore(true_id_list,predicted_id_list,i)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1_score)\n",
    "    \n",
    "    return precision_list,recall_list,f1_score_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ddfd3",
   "metadata": {},
   "source": [
    "# Comparing ChatGPT against Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "410a579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list, recall_list , f1_score_list = evaluateModel(manual_ner_list,chatgpt_ner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40526180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.6384709629992648\n",
      "Recall  0.5559982983628303\n",
      "Macro-F1-Score  0.520102990691226\n"
     ]
    }
   ],
   "source": [
    "# Computing Macro Score\n",
    "def average(lst):\n",
    "    if not lst:\n",
    "        return 0  # return 0 if the list is empty to avoid division by zero\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "print(\"Precision \"  ,average(precision_list))\n",
    "print(\"Recall \" ,average(recall_list))\n",
    "print(\"Macro-F1-Score \" , average(f1_score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "465b1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataframe(labels,precision_list,recall_list,f1_score_list):\n",
    "    data = {'Label': list(labels.keys()),\n",
    "        'Precision': precision_list,\n",
    "        'Recall': recall_list,\n",
    "        'F1-Score': f1_score_list}\n",
    "    return pd.DataFrame(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c34ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "-----------------------------------ChatGPT------------------------------------------\n",
      "-------------------------------------------------------------------------------------\n",
      "    Label  Precision    Recall  F1-Score\n",
      "0       O   0.917667  0.992579  0.953654\n",
      "1   B-PER   1.000000  0.500000  0.666667\n",
      "2   I-PER   0.750000  1.000000  0.857143\n",
      "3   B-ORG   0.400000  0.400000  0.400000\n",
      "4   I-ORG   0.000000  0.000000  0.000000\n",
      "5   B-LOC   0.428571  1.000000  0.600000\n",
      "6   I-LOC   1.000000  1.000000  1.000000\n",
      "7  B-MISC   0.250000  0.034483  0.060606\n",
      "8  I-MISC   1.000000  0.076923  0.142857\n",
      "Macro-F1-Score :  0.520102990691226\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Indic NER\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"-----------------------------------ChatGPT------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "indic_ner_dataframe = getDataframe(label_list,precision_list, recall_list , f1_score_list)\n",
    "print(indic_ner_dataframe)\n",
    "\n",
    "# Macro F1 - Score\n",
    "print(\"Macro-F1-Score : \" , sum(f1_score_list) / len(f1_score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef71c89",
   "metadata": {},
   "source": [
    "# Comparing IndicNER and Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f2b3c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\study\\anaconda\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in d:\\study\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\study\\anaconda\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\study\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\study\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\study\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\study\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\study\\anaconda\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\study\\anaconda\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\study\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in d:\\study\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\study\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\study\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\study\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\study\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\study\\anaconda\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: transformers[torch] in d:\\study\\anaconda\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in d:\\study\\anaconda\\lib\\site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec in d:\\study\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\study\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in d:\\study\\anaconda\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\study\\anaconda\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\study\\anaconda\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\study\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\study\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\study\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\study\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\study\\anaconda\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\study\\anaconda\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6b340c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c894185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config_indic_ner = json.load(open(\"./model_fine_tune_indicner/config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1159dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list_config = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b92978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n",
      "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'}\n"
     ]
    }
   ],
   "source": [
    "label2id = {\n",
    "    str(i): label for i,label in label_list_config.items()\n",
    "}\n",
    "id2label = {\n",
    "    label: str(i) for i,label in label_list_config.items()\n",
    "}\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb463911",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_indic_ner[\"id2label\"] = id2label\n",
    "config_indic_ner[\"label2id\"] = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccf70767",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(config_indic_ner, open(\"./model_fine_tune_indicner/config.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3da2ed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Study\\Anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "D:\\Study\\Anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "model_indic_ner = AutoModelForTokenClassification.from_pretrained('./model_fine_tune_indicner')\n",
    "tokenizer_indic_ner = AutoTokenizer.from_pretrained(\"./model_fine_tune_indicner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91973c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"./model_fine_tune_indicner\",\n",
       "  \"architectures\": [\n",
       "    \"BertForTokenClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"finetuning_task\": \"ner\",\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-PER\",\n",
       "    \"2\": \"I-PER\",\n",
       "    \"3\": \"B-ORG\",\n",
       "    \"4\": \"I-ORG\",\n",
       "    \"5\": \"B-LOC\",\n",
       "    \"6\": \"I-LOC\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"B-LOC\": 5,\n",
       "    \"B-ORG\": 3,\n",
       "    \"B-PER\": 1,\n",
       "    \"I-LOC\": 6,\n",
       "    \"I-ORG\": 4,\n",
       "    \"I-PER\": 2,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.32.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 105879\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_indic_ner.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a051b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(sentence,model,tokenizer):\n",
    "    tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tok_sentence).logits.argmax(-1)\n",
    "#         print(logits)\n",
    "        predicted_tokens_classes = [\n",
    "            model.config.id2label[t.item()] for t in logits[0]]\n",
    "#         print(predicted_tokens_classes)\n",
    "        predicted_labels = []\n",
    "\n",
    "        previous_token_id = 0\n",
    "        word_ids = tok_sentence.word_ids()\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] == None:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            elif word_ids[word_index] == previous_token_id:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            else:\n",
    "                predicted_labels.append(predicted_tokens_classes[word_index])\n",
    "                previous_token_id = word_ids[word_index]\n",
    "\n",
    "        ner_output = []\n",
    "        for index in range(len(sentence.split(' '))):\n",
    "            if(index<len(predicted_labels)):\n",
    "                ner_output.append((sentence.split(' ')[index], predicted_labels[index]))\n",
    "            else:\n",
    "                ner_output.append((sentence.split(' ')[index], 'O'))\n",
    "        return ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a74511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('अब', 'O'), ('आर-पार', 'B-LOC'), ('की', 'I-LOC'), ('लड़ाई', 'I-LOC'), ('लड़ने', 'O'), ('का', 'O'), ('ऐलान', 'O'), ('करते', 'O'), ('हुए', 'O'), ('दूसरे', 'O'), ('विभागों', 'O'), ('के', 'O'), ('कर्मचारी', 'O'), ('भी', 'O'), ('समर्थन', 'O'), ('में', 'O'), ('आ', 'O'), ('गए', 'O'), ('हैं।\\n', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(get_ner(manual_sentence_list[0],model_indic_ner,tokenizer_indic_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f243e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataframe(labels,precision_list,recall_list,f1_score_list):\n",
    "    data = {'Label': list(label_list.keys()),\n",
    "        'Precision': precision_list,\n",
    "        'Recall': recall_list,\n",
    "        'F1-Score': f1_score_list}\n",
    "    return pd.DataFrame(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b7837de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding NER Tags for IndicNER\n",
    "IndicNER_ner_list_irregular = []\n",
    "for i in range(25):\n",
    "    temp_list = get_ner(manual_sentence_list[i],model_indic_ner,tokenizer_indic_ner)\n",
    "    line_ner_list = []\n",
    "    for tuple_pair in temp_list:\n",
    "        line_ner_list.append(tuple_pair[1])\n",
    "    IndicNER_ner_list_irregular.append(line_ner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "840820fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 577, 'B-LOC': 6, 'I-LOC': 3, 'B-ORG': 6, 'B-PER': 13, 'I-PER': 8, 'I-ORG': 8}\n"
     ]
    }
   ],
   "source": [
    "count = {}\n",
    "for i in range(25):\n",
    "    for tag in IndicNER_ner_list_irregular[i]:\n",
    "        if tag in count:\n",
    "            count[tag]+=1\n",
    "        else:\n",
    "            count[tag]=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56bd94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Irregular Shape of IndicNER\n",
    "IndicNER_ner_list = []\n",
    "for i in range(25):\n",
    "    if len(IndicNER_ner_list_irregular[i]) > len(manual_ner_list[i]):\n",
    "        difference = len(IndicNER_ner_list_irregular[i]) - len(manual_ner_list[i])\n",
    "        IndicNER_ner_list.append(IndicNER_ner_list_irregular[i][:-difference])\n",
    "    elif len(IndicNER_ner_list_irregular[i]) < len(manual_ner_list[i]):\n",
    "        difference = len(manual_ner_list[i]) - len(IndicNER_ner_list_irregular[i])\n",
    "        IndicNER_ner_list_irregular[i] += ['O'] * difference\n",
    "        IndicNER_ner_list.append(IndicNER_ner_list_irregular[i])\n",
    "    else:\n",
    "        IndicNER_ner_list.append(IndicNER_ner_list_irregular[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2adddf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Study\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Study\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "precision_list, recall_list , f1_score_list = evaluateModel(manual_ner_list,IndicNER_ner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a74b952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "-----------------------------------IndicNER------------------------------------------\n",
      "-------------------------------------------------------------------------------------\n",
      "    Label  Precision    Recall  F1-Score\n",
      "0       O   0.912892  0.972171  0.941599\n",
      "1   B-PER   0.615385  0.500000  0.551724\n",
      "2   I-PER   0.500000  0.666667  0.571429\n",
      "3   B-ORG   0.500000  0.600000  0.545455\n",
      "4   I-ORG   0.625000  0.833333  0.714286\n",
      "5   B-LOC   0.500000  1.000000  0.666667\n",
      "6   I-LOC   0.333333  1.000000  0.500000\n",
      "7  B-MISC   0.000000  0.000000  0.000000\n",
      "8  I-MISC   0.000000  0.000000  0.000000\n",
      "Macro-F1-Score :  0.49901765744316173\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Indic NER\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"-----------------------------------IndicNER------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "indic_ner_dataframe = getDataframe(label_list,precision_list, recall_list , f1_score_list)\n",
    "print(indic_ner_dataframe)\n",
    "\n",
    "# Macro F1 - Score\n",
    "print(\"Macro-F1-Score : \" , sum(f1_score_list) / len(f1_score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca5873",
   "metadata": {},
   "source": [
    "# Comparing IndicBERT and Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3c6ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Study\\Anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "config_indicbert = json.load(open(\"./model_fine_tune_indicbert/config.json\"))\n",
    "config_indicbert[\"id2label\"] = id2label\n",
    "config_indicbert[\"label2id\"] = label2id\n",
    "json.dump(config_indicbert, open(\"./model_fine_tune_indicbert/config.json\",\"w\"))\n",
    "\n",
    "model_indicbert = AutoModelForTokenClassification.from_pretrained('./model_fine_tune_indicbert')\n",
    "tokenizer_indicbert = AutoTokenizer.from_pretrained(\"./model_fine_tune_indicbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "797a5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Bert Tags for IndicBERT\n",
    "Indicbert_ner_list_irregular = []\n",
    "for i in range(25):\n",
    "    temp_list = get_ner(manual_sentence_list[i],model_indicbert,tokenizer_indicbert)\n",
    "    line_ner_list = []\n",
    "    for tuple_pair in temp_list:\n",
    "        line_ner_list.append(tuple_pair[1])\n",
    "    Indicbert_ner_list_irregular.append(line_ner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07646a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Irregular Shape of IndicBERT\n",
    "IndicBert_ner_list = []\n",
    "for i in range(25):\n",
    "    if len(Indicbert_ner_list_irregular[i]) > len(manual_ner_list[i]):\n",
    "        difference = len(Indicbert_ner_list_irregular[i]) - len(manual_ner_list[i])\n",
    "        IndicBert_ner_list.append(Indicbert_ner_list_irregular[i][:-difference])\n",
    "    elif len(Indicbert_ner_list_irregular[i]) < len(manual_ner_list[i]):\n",
    "        difference = len(manual_ner_list[i]) - len(Indicbert_ner_list_irregular[i])\n",
    "        Indicbert_ner_list_irregular[i] += ['O'] * difference\n",
    "        IndicBert_ner_list.append(Indicbert_ner_list_irregular[i])\n",
    "    else:\n",
    "        IndicBert_ner_list.append(Indicbert_ner_list_irregular[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c19fbfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Study\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Study\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "precision_list, recall_list , f1_score_list = evaluateModel(manual_ner_list,IndicBert_ner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01de2818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Label  Precision    Recall  F1-Score\n",
      "0       O   0.906412  0.970315  0.937276\n",
      "1   B-PER   0.400000  0.375000  0.387097\n",
      "2   I-PER   0.714286  0.833333  0.769231\n",
      "3   B-ORG   0.571429  0.800000  0.666667\n",
      "4   I-ORG   0.750000  0.500000  0.600000\n",
      "5   B-LOC   0.285714  0.666667  0.400000\n",
      "6   I-LOC   1.000000  1.000000  1.000000\n",
      "7  B-MISC   0.000000  0.000000  0.000000\n",
      "8  I-MISC   0.000000  0.000000  0.000000\n",
      "Macro-F1-Score :  0.5289189106393407\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Indic IndicBERT\n",
    "indic_bert_dataframe = getDataframe(label_list,precision_list, recall_list , f1_score_list)\n",
    "print(indic_bert_dataframe)\n",
    "\n",
    "# Macro F1 - Score\n",
    "print(\"Macro-F1-Score : \" , sum(f1_score_list) / len(f1_score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b285a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e956c49ae0caa224b5fdd754cbc353d7e61c6c61f7329ee680c7f7b4f1b71a8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
