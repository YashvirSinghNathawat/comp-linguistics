{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip3 install datasets\n",
    "!pip3 install sentencepiece\n",
    "!pip3 install seqeval\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T10:42:35.743888Z",
     "iopub.status.busy": "2024-03-13T10:42:35.743589Z",
     "iopub.status.idle": "2024-03-13T10:42:37.765923Z",
     "shell.execute_reply": "2024-03-13T10:42:37.765126Z",
     "shell.execute_reply.started": "2024-03-13T10:42:35.743863Z"
    }
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:56:41.319413Z",
     "iopub.status.busy": "2024-03-13T13:56:41.318997Z",
     "iopub.status.idle": "2024-03-13T13:56:42.778968Z",
     "shell.execute_reply": "2024-03-13T13:56:42.777868Z",
     "shell.execute_reply.started": "2024-03-13T13:56:41.319387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's download the Naampadam (Indic NER) dataset\n",
    "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
    "\n",
    "lang='hi'\n",
    "\n",
    "train_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'train[:20000]')\n",
    "validation_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'validation')\n",
    "test_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:56:44.772017Z",
     "iopub.status.busy": "2024-03-13T13:56:44.771667Z",
     "iopub.status.idle": "2024-03-13T13:56:44.778955Z",
     "shell.execute_reply": "2024-03-13T13:56:44.777911Z",
     "shell.execute_reply.started": "2024-03-13T13:56:44.771990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "features = train_dataset.features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:56:48.915287Z",
     "iopub.status.busy": "2024-03-13T13:56:48.914385Z",
     "iopub.status.idle": "2024-03-13T13:56:48.922429Z",
     "shell.execute_reply": "2024-03-13T13:56:48.921330Z",
     "shell.execute_reply.started": "2024-03-13T13:56:48.915242Z"
    }
   },
   "outputs": [],
   "source": [
    "text_column_name = \"tokens\"\n",
    "label_column_name = \"ner_tags\"\n",
    "\n",
    "label_list = features[label_column_name].feature.names\n",
    "\n",
    "label_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n",
    "\n",
    "num_labels = len(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:56:59.335297Z",
     "iopub.status.busy": "2024-03-13T13:56:59.334917Z",
     "iopub.status.idle": "2024-03-13T13:56:59.993008Z",
     "shell.execute_reply": "2024-03-13T13:56:59.991992Z",
     "shell.execute_reply.started": "2024-03-13T13:56:59.335267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining Base Model and tokenizer\n",
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "config = AutoConfig.from_pretrained('ai4bharat/IndicNER', num_labels=num_labels, finetuning_task='ner')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"ai4bharat/IndicNER\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:58:57.015777Z",
     "iopub.status.busy": "2024-03-13T13:58:57.015360Z",
     "iopub.status.idle": "2024-03-13T13:58:57.026039Z",
     "shell.execute_reply": "2024-03-13T13:58:57.025072Z",
     "shell.execute_reply.started": "2024-03-13T13:58:57.015747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize all texts and align the labels with them.\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "    # print(tokenized_inputs)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[label_column_name]):\n",
    "        # print('=====')\n",
    "        # print('{} {}'.format(i,label)) #ak\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    # print(tokenized_inputs)\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:59:17.788526Z",
     "iopub.status.busy": "2024-03-13T13:59:17.787832Z",
     "iopub.status.idle": "2024-03-13T13:59:17.796048Z",
     "shell.execute_reply": "2024-03-13T13:59:17.794573Z",
     "shell.execute_reply.started": "2024-03-13T13:59:17.788492Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_output = tokenize_and_align_labels(train_dataset[0:1])\n",
    "tokens = tokenizer.convert_ids_to_tokens(correct_output[\"input_ids\"][0])\n",
    "\n",
    "# Now we have input ids and labels to pass to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:59:38.159755Z",
     "iopub.status.busy": "2024-03-13T13:59:38.158934Z",
     "iopub.status.idle": "2024-03-13T13:59:47.034801Z",
     "shell.execute_reply": "2024-03-13T13:59:47.033770Z",
     "shell.execute_reply.started": "2024-03-13T13:59:38.159725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b9b69827d2452a98f83fd6ab8642fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 20000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing Train Dataset\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    ")\n",
    "print(tokenized_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:59:50.329295Z",
     "iopub.status.busy": "2024-03-13T13:59:50.328937Z",
     "iopub.status.idle": "2024-03-13T13:59:50.340733Z",
     "shell.execute_reply": "2024-03-13T13:59:50.339538Z",
     "shell.execute_reply.started": "2024-03-13T13:59:50.329266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# Problem of uneven length is fixed now!!\n",
    "print(len(tokenized_train_dataset[0]['ner_tags']))\n",
    "print(len(tokenized_train_dataset[0]['labels']))\n",
    "print(len(tokenized_train_dataset[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:59:50.612697Z",
     "iopub.status.busy": "2024-03-13T13:59:50.612386Z",
     "iopub.status.idle": "2024-03-13T13:59:51.009808Z",
     "shell.execute_reply": "2024-03-13T13:59:51.008685Z",
     "shell.execute_reply.started": "2024-03-13T13:59:50.612670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e7fb86a45e4f24b6f5d7ba25c3bc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 867\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing Test Dataset\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    ")\n",
    "print(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:59:56.335866Z",
     "iopub.status.busy": "2024-03-13T13:59:56.334971Z",
     "iopub.status.idle": "2024-03-13T14:00:02.053221Z",
     "shell.execute_reply": "2024-03-13T14:00:02.051952Z",
     "shell.execute_reply.started": "2024-03-13T13:59:56.335833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca7d260e5cf459697331b57ac165ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 13460\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing Validation DataSet\n",
    "tokenized_validation_dataset = validation_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    ")\n",
    "print(tokenized_validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:00:06.361448Z",
     "iopub.status.busy": "2024-03-13T14:00:06.360705Z",
     "iopub.status.idle": "2024-03-13T14:00:06.367049Z",
     "shell.execute_reply": "2024-03-13T14:00:06.366013Z",
     "shell.execute_reply.started": "2024-03-13T14:00:06.361417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:00:08.402888Z",
     "iopub.status.busy": "2024-03-13T14:00:08.401889Z",
     "iopub.status.idle": "2024-03-13T14:00:08.704816Z",
     "shell.execute_reply": "2024-03-13T14:00:08.703499Z",
     "shell.execute_reply.started": "2024-03-13T14:00:08.402851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metric to see how my model is performing For NER we use seqeval\n",
    "metric = datasets.load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:00:16.923459Z",
     "iopub.status.busy": "2024-03-13T14:00:16.922782Z",
     "iopub.status.idle": "2024-03-13T14:00:16.946234Z",
     "shell.execute_reply": "2024-03-13T14:00:16.945004Z",
     "shell.execute_reply.started": "2024-03-13T14:00:16.923426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing the working of seqeval\n",
    "example_text = train_dataset[0]\n",
    "label_list = train_dataset.features[\"ner_tags\"].feature.names\n",
    "label_list\n",
    "\n",
    "labels = [label_list[i] for i in example_text[\"ner_tags\"]]\n",
    "# print(labels)\n",
    "\n",
    "metric.compute(predictions=[labels] , references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:00:18.085113Z",
     "iopub.status.busy": "2024-03-13T14:00:18.084207Z",
     "iopub.status.idle": "2024-03-13T14:00:18.330702Z",
     "shell.execute_reply": "2024-03-13T14:00:18.329746Z",
     "shell.execute_reply.started": "2024-03-13T14:00:18.085054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    # Unpack nested dictionaries\n",
    "    final_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for n, v in value.items():\n",
    "                final_results[f\"{key}_{n}\"] = v\n",
    "        else:\n",
    "            final_results[key] = value\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:01:01.204830Z",
     "iopub.status.busy": "2024-03-13T14:01:01.204462Z",
     "iopub.status.idle": "2024-03-13T14:01:01.220552Z",
     "shell.execute_reply": "2024-03-13T14:01:01.219531Z",
     "shell.execute_reply.started": "2024-03-13T14:01:01.204803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Training Args\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"model/upos\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=10,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.001,\n",
    "    save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:01:14.438035Z",
     "iopub.status.busy": "2024-03-13T14:01:14.437644Z",
     "iopub.status.idle": "2024-03-13T14:01:14.631603Z",
     "shell.execute_reply": "2024-03-13T14:01:14.630521Z",
     "shell.execute_reply.started": "2024-03-13T14:01:14.438007Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "   model,\n",
    "   args,\n",
    "   train_dataset=tokenized_train_dataset,\n",
    "   eval_dataset=tokenized_validation_dataset,\n",
    "   data_collator=data_collator,\n",
    "   tokenizer=tokenizer,\n",
    "   compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:01:16.888307Z",
     "iopub.status.busy": "2024-03-13T14:01:16.887842Z",
     "iopub.status.idle": "2024-03-13T14:47:38.719110Z",
     "shell.execute_reply": "2024-03-13T14:47:38.718215Z",
     "shell.execute_reply.started": "2024-03-13T14:01:16.888275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 46:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loc Precision</th>\n",
       "      <th>Loc Recall</th>\n",
       "      <th>Loc F1</th>\n",
       "      <th>Loc Number</th>\n",
       "      <th>Org Precision</th>\n",
       "      <th>Org Recall</th>\n",
       "      <th>Org F1</th>\n",
       "      <th>Org Number</th>\n",
       "      <th>Per Precision</th>\n",
       "      <th>Per Recall</th>\n",
       "      <th>Per F1</th>\n",
       "      <th>Per Number</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.723500</td>\n",
       "      <td>0.190422</td>\n",
       "      <td>0.802007</td>\n",
       "      <td>0.829335</td>\n",
       "      <td>0.815442</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.673067</td>\n",
       "      <td>0.662681</td>\n",
       "      <td>0.667834</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.768656</td>\n",
       "      <td>0.837245</td>\n",
       "      <td>0.801486</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.750718</td>\n",
       "      <td>0.778716</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.945071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.178656</td>\n",
       "      <td>0.811047</td>\n",
       "      <td>0.846862</td>\n",
       "      <td>0.828567</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.674806</td>\n",
       "      <td>0.694666</td>\n",
       "      <td>0.684592</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.804291</td>\n",
       "      <td>0.837245</td>\n",
       "      <td>0.820437</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.765462</td>\n",
       "      <td>0.794811</td>\n",
       "      <td>0.779861</td>\n",
       "      <td>0.947673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.141300</td>\n",
       "      <td>0.178792</td>\n",
       "      <td>0.822199</td>\n",
       "      <td>0.850778</td>\n",
       "      <td>0.836245</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.683327</td>\n",
       "      <td>0.690170</td>\n",
       "      <td>0.686731</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.802456</td>\n",
       "      <td>0.841030</td>\n",
       "      <td>0.821290</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.771727</td>\n",
       "      <td>0.795989</td>\n",
       "      <td>0.783670</td>\n",
       "      <td>0.948147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.176748</td>\n",
       "      <td>0.818343</td>\n",
       "      <td>0.857045</td>\n",
       "      <td>0.837247</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.679073</td>\n",
       "      <td>0.697323</td>\n",
       "      <td>0.688077</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.801317</td>\n",
       "      <td>0.840367</td>\n",
       "      <td>0.820378</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.768443</td>\n",
       "      <td>0.800144</td>\n",
       "      <td>0.783973</td>\n",
       "      <td>0.948331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.180346</td>\n",
       "      <td>0.810089</td>\n",
       "      <td>0.861647</td>\n",
       "      <td>0.835073</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.672086</td>\n",
       "      <td>0.697016</td>\n",
       "      <td>0.684324</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.802645</td>\n",
       "      <td>0.838569</td>\n",
       "      <td>0.820214</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.763829</td>\n",
       "      <td>0.800962</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.947719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.179577</td>\n",
       "      <td>0.814822</td>\n",
       "      <td>0.859101</td>\n",
       "      <td>0.836376</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.678874</td>\n",
       "      <td>0.697118</td>\n",
       "      <td>0.687875</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.803396</td>\n",
       "      <td>0.837150</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.767947</td>\n",
       "      <td>0.799653</td>\n",
       "      <td>0.783480</td>\n",
       "      <td>0.948143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory model/upos/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:04:05.526790Z",
     "iopub.status.busy": "2024-03-13T15:04:05.525909Z",
     "iopub.status.idle": "2024-03-13T15:04:07.333165Z",
     "shell.execute_reply": "2024-03-13T15:04:07.332138Z",
     "shell.execute_reply.started": "2024-03-13T15:04:05.526760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "trainer.save_model(\"model_indic_ner_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:04:19.405721Z",
     "iopub.status.busy": "2024-03-13T15:04:19.405354Z",
     "iopub.status.idle": "2024-03-13T15:04:25.919672Z",
     "shell.execute_reply": "2024-03-13T15:04:25.918468Z",
     "shell.execute_reply.started": "2024-03-13T15:04:19.405694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='directory.zip' target='_blank'>directory.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/directory.zip"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "def zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n",
    "    \"\"\"\n",
    "    zip all the files in a directory\n",
    "    \n",
    "    Parameters\n",
    "    ___\n",
    "    directory: str\n",
    "        directory needs to be zipped, defualt is current working directory\n",
    "        \n",
    "    file_name: str\n",
    "        the name of the zipped file (including .zip), default is 'directory.zip'\n",
    "        \n",
    "    Returns\n",
    "    ___\n",
    "    Creates a hyperlink, which can be used to download the zip file)\n",
    "    \"\"\"\n",
    "    os.chdir(directory)\n",
    "    zip_ref = zipfile.ZipFile(file_name, mode='w')\n",
    "    for folder, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file_name in file:\n",
    "                pass\n",
    "            else:\n",
    "                zip_ref.write(os.path.join(folder, file))\n",
    "\n",
    "    return FileLink(file_name)\n",
    "zip_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:04:42.217229Z",
     "iopub.status.busy": "2024-03-13T15:04:42.216342Z",
     "iopub.status.idle": "2024-03-13T15:07:23.247682Z",
     "shell.execute_reply": "2024-03-13T15:07:23.245793Z",
     "shell.execute_reply.started": "2024-03-13T15:04:42.217195Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_LOC_f1             =     0.8364\n",
      "  eval_LOC_number         =      10213\n",
      "  eval_LOC_precision      =     0.8148\n",
      "  eval_LOC_recall         =     0.8591\n",
      "  eval_ORG_f1             =     0.6879\n",
      "  eval_ORG_number         =       9786\n",
      "  eval_ORG_precision      =     0.6789\n",
      "  eval_ORG_recall         =     0.6971\n",
      "  eval_PER_f1             =     0.8199\n",
      "  eval_PER_number         =      10568\n",
      "  eval_PER_precision      =     0.8034\n",
      "  eval_PER_recall         =     0.8371\n",
      "  eval_loss               =     0.1796\n",
      "  eval_overall_accuracy   =     0.9481\n",
      "  eval_overall_f1         =     0.7835\n",
      "  eval_overall_precision  =     0.7679\n",
      "  eval_overall_recall     =     0.7997\n",
      "  eval_runtime            = 0:02:41.01\n",
      "  eval_samples_per_second =     83.596\n",
      "  eval_steps_per_second   =       4.18\n"
     ]
    }
   ],
   "source": [
    "Final_metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"Validation eval\", Final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:11:51.171353Z",
     "iopub.status.busy": "2024-03-13T15:11:51.170644Z",
     "iopub.status.idle": "2024-03-13T15:15:48.739319Z",
     "shell.execute_reply": "2024-03-13T15:15:48.738267Z",
     "shell.execute_reply.started": "2024-03-13T15:11:51.171319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  test_LOC_f1             =     0.8751\n",
      "  test_LOC_number         =      14841\n",
      "  test_LOC_precision      =     0.8558\n",
      "  test_LOC_recall         =     0.8954\n",
      "  test_ORG_f1             =      0.772\n",
      "  test_ORG_number         =      14082\n",
      "  test_ORG_precision      =     0.7626\n",
      "  test_ORG_recall         =     0.7816\n",
      "  test_PER_f1             =     0.8739\n",
      "  test_PER_number         =      15614\n",
      "  test_PER_precision      =     0.8624\n",
      "  test_PER_recall         =     0.8857\n",
      "  test_loss               =     0.1055\n",
      "  test_overall_accuracy   =     0.9667\n",
      "  test_overall_f1         =     0.8422\n",
      "  test_overall_precision  =     0.8289\n",
      "  test_overall_recall     =      0.856\n",
      "  test_runtime            = 0:03:57.54\n",
      "  test_samples_per_second =     84.195\n",
      "  test_steps_per_second   =       4.21\n",
      "\n",
      " Macro f1 score:: 0.8403391476998284\n"
     ]
    }
   ],
   "source": [
    "# Testing on Training dataset\n",
    "predictions, labels, metrics = trainer.predict(tokenized_train_dataset)\n",
    "trainer.log_metrics(\"train\",metrics)\n",
    "\n",
    "sum_of_f1_scores=metrics['test_LOC_f1']+metrics['test_ORG_f1']+metrics['test_PER_f1']\n",
    "macro_f1=sum_of_f1_scores/3\n",
    "print('\\n Testing Macro f1 score::',macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on 20% Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:17:37.796759Z",
     "iopub.status.busy": "2024-03-13T15:17:37.796108Z",
     "iopub.status.idle": "2024-03-13T15:17:38.270122Z",
     "shell.execute_reply": "2024-03-13T15:17:38.269023Z",
     "shell.execute_reply.started": "2024-03-13T15:17:37.796727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 867\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
    "lang = 'hi'\n",
    "test_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'test')\n",
    "# Test Dataset\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    ")\n",
    "print(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:17:42.824608Z",
     "iopub.status.busy": "2024-03-13T15:17:42.824226Z",
     "iopub.status.idle": "2024-03-13T15:17:53.103542Z",
     "shell.execute_reply": "2024-03-13T15:17:53.102382Z",
     "shell.execute_reply.started": "2024-03-13T15:17:42.824580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Test metrics *****\n",
      "  test_LOC_f1             =     0.8136\n",
      "  test_LOC_number         =        614\n",
      "  test_LOC_precision      =     0.8097\n",
      "  test_LOC_recall         =     0.8176\n",
      "  test_ORG_f1             =     0.7134\n",
      "  test_ORG_number         =        525\n",
      "  test_ORG_precision      =      0.654\n",
      "  test_ORG_recall         =     0.7848\n",
      "  test_PER_f1             =     0.8745\n",
      "  test_PER_number         =        790\n",
      "  test_PER_precision      =     0.8427\n",
      "  test_PER_recall         =     0.9089\n",
      "  test_loss               =     0.1444\n",
      "  test_overall_accuracy   =     0.9567\n",
      "  test_overall_f1         =     0.8097\n",
      "  test_overall_precision  =     0.7764\n",
      "  test_overall_recall     =      0.846\n",
      "  test_runtime            = 0:00:10.25\n",
      "  test_samples_per_second =     84.584\n",
      "  test_steps_per_second   =      4.293\n",
      "\n",
      " Macro f1 score:: 0.8005258053106568\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Model on test Data\n",
    "predictions, labels, metrics = trainer.predict(tokenized_test_dataset)\n",
    "trainer.log_metrics(\"Test\",metrics)\n",
    "\n",
    "sum_of_f1_scores=metrics['test_LOC_f1']+metrics['test_ORG_f1']+metrics['test_PER_f1']\n",
    "macro_f1=sum_of_f1_scores/3\n",
    "print('\\n Macro f1 score::',macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
