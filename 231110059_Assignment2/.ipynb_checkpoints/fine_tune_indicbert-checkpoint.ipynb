{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip3 install datasets\n",
    "!pip3 install sentencepiece\n",
    "!pip3 install seqeval\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:44:56.485403Z",
     "iopub.status.busy": "2024-03-13T13:44:56.484555Z",
     "iopub.status.idle": "2024-03-13T13:44:56.490706Z",
     "shell.execute_reply": "2024-03-13T13:44:56.489611Z",
     "shell.execute_reply.started": "2024-03-13T13:44:56.485372Z"
    }
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:44:56.787021Z",
     "iopub.status.busy": "2024-03-13T13:44:56.786702Z",
     "iopub.status.idle": "2024-03-13T13:44:58.934243Z",
     "shell.execute_reply": "2024-03-13T13:44:58.933134Z",
     "shell.execute_reply.started": "2024-03-13T13:44:56.786996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's download the Naampadam (Indic NER) dataset\n",
    "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
    "\n",
    "lang='hi'\n",
    "\n",
    "train_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'train[:20000]')\n",
    "validation_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'validation')\n",
    "test_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:45:09.834775Z",
     "iopub.status.busy": "2024-03-13T13:45:09.834392Z",
     "iopub.status.idle": "2024-03-13T13:45:09.841716Z",
     "shell.execute_reply": "2024-03-13T13:45:09.840426Z",
     "shell.execute_reply.started": "2024-03-13T13:45:09.834743Z"
    }
   },
   "outputs": [],
   "source": [
    "text_column_name = \"tokens\"\n",
    "label_column_name = \"ner_tags\"\n",
    "\n",
    "label_list = features[label_column_name].feature.names\n",
    "\n",
    "label_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n",
    "\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:45:13.692655Z",
     "iopub.status.busy": "2024-03-13T13:45:13.691914Z",
     "iopub.status.idle": "2024-03-13T13:45:16.765649Z",
     "shell.execute_reply": "2024-03-13T13:45:16.764511Z",
     "shell.execute_reply.started": "2024-03-13T13:45:13.692622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Import Models and Tokenizer\n",
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "import numpy as np\n",
    "\n",
    "config = AutoConfig.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels, finetuning_task='ner')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:45:53.985525Z",
     "iopub.status.busy": "2024-03-13T13:45:53.984800Z",
     "iopub.status.idle": "2024-03-13T13:45:53.994978Z",
     "shell.execute_reply": "2024-03-13T13:45:53.993938Z",
     "shell.execute_reply.started": "2024-03-13T13:45:53.985490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize all texts and align the labels with them.\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "    # print(tokenized_inputs)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[label_column_name]):\n",
    "        # print('=====')\n",
    "        # print('{} {}'.format(i,label)) #ak\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    # print(tokenized_inputs)\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_output = tokenize_and_align_labels(train_dataset[0:1])\n",
    "tokens = tokenizer.convert_ids_to_tokens(correct_output[\"input_ids\"][0])\n",
    "# print(tokens)\n",
    "\n",
    "# Now we have input ids and labels to pass to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:46:33.966621Z",
     "iopub.status.busy": "2024-03-13T13:46:33.966240Z",
     "iopub.status.idle": "2024-03-13T13:46:42.608979Z",
     "shell.execute_reply": "2024-03-13T13:46:42.607912Z",
     "shell.execute_reply.started": "2024-03-13T13:46:33.966590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7200e7e98914339add10efce8c77622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 20000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing Train Dataset\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    ")\n",
    "print(tokenized_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:46:23.548306Z",
     "iopub.status.busy": "2024-03-13T13:46:23.547913Z",
     "iopub.status.idle": "2024-03-13T13:46:23.561496Z",
     "shell.execute_reply": "2024-03-13T13:46:23.560156Z",
     "shell.execute_reply.started": "2024-03-13T13:46:23.548275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# Problem is fixed now!!\n",
    "print(len(tokenized_train_dataset[0]['ner_tags']))\n",
    "print(len(tokenized_train_dataset[0]['labels']))\n",
    "print(len(tokenized_train_dataset[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:46:26.864689Z",
     "iopub.status.busy": "2024-03-13T13:46:26.864331Z",
     "iopub.status.idle": "2024-03-13T13:46:27.262028Z",
     "shell.execute_reply": "2024-03-13T13:46:27.261122Z",
     "shell.execute_reply.started": "2024-03-13T13:46:26.864661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84db585b0de046ab807cc23248568a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 867\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Test Dataset\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    ")\n",
    "print(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:46:58.646515Z",
     "iopub.status.busy": "2024-03-13T13:46:58.645774Z",
     "iopub.status.idle": "2024-03-13T13:47:04.791448Z",
     "shell.execute_reply": "2024-03-13T13:47:04.790504Z",
     "shell.execute_reply.started": "2024-03-13T13:46:58.646478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a5c1718454489695cd42bf73fa3b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 13460\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Validation DataSet\n",
    "tokenized_validation_dataset = validation_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    ")\n",
    "print(tokenized_validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:47:07.842024Z",
     "iopub.status.busy": "2024-03-13T13:47:07.841655Z",
     "iopub.status.idle": "2024-03-13T13:47:07.847889Z",
     "shell.execute_reply": "2024-03-13T13:47:07.846782Z",
     "shell.execute_reply.started": "2024-03-13T13:47:07.841992Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:47:10.922896Z",
     "iopub.status.busy": "2024-03-13T13:47:10.922188Z",
     "iopub.status.idle": "2024-03-13T13:47:11.452483Z",
     "shell.execute_reply": "2024-03-13T13:47:11.451477Z",
     "shell.execute_reply.started": "2024-03-13T13:47:10.922867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metric to see how my model is performing For NER we use seqeval\n",
    "metric = datasets.load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:47:17.755592Z",
     "iopub.status.busy": "2024-03-13T13:47:17.755069Z",
     "iopub.status.idle": "2024-03-13T13:47:17.773253Z",
     "shell.execute_reply": "2024-03-13T13:47:17.772106Z",
     "shell.execute_reply.started": "2024-03-13T13:47:17.755552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing the working of seqeval\n",
    "example_text = train_dataset[0]\n",
    "label_list = train_dataset.features[\"ner_tags\"].feature.names\n",
    "label_list\n",
    "\n",
    "labels = [label_list[i] for i in example_text[\"ner_tags\"]]\n",
    "# print(labels)\n",
    "\n",
    "metric.compute(predictions=[labels] , references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:47:23.276791Z",
     "iopub.status.busy": "2024-03-13T13:47:23.276036Z",
     "iopub.status.idle": "2024-03-13T13:47:23.628105Z",
     "shell.execute_reply": "2024-03-13T13:47:23.626943Z",
     "shell.execute_reply.started": "2024-03-13T13:47:23.276754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    # Unpack nested dictionaries\n",
    "    final_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for n, v in value.items():\n",
    "                final_results[f\"{key}_{n}\"] = v\n",
    "        else:\n",
    "            final_results[key] = value\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:51:07.154671Z",
     "iopub.status.busy": "2024-03-13T13:51:07.153537Z",
     "iopub.status.idle": "2024-03-13T13:51:07.164227Z",
     "shell.execute_reply": "2024-03-13T13:51:07.163097Z",
     "shell.execute_reply.started": "2024-03-13T13:51:07.154627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Training Args\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"model/upos\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:51:07.982417Z",
     "iopub.status.busy": "2024-03-13T13:51:07.981586Z",
     "iopub.status.idle": "2024-03-13T13:51:07.995418Z",
     "shell.execute_reply": "2024-03-13T13:51:07.994387Z",
     "shell.execute_reply.started": "2024-03-13T13:51:07.982382Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "   model,\n",
    "   args,\n",
    "   train_dataset=tokenized_train_dataset,\n",
    "   eval_dataset=tokenized_validation_dataset,\n",
    "   data_collator=data_collator,\n",
    "   tokenizer=tokenizer,\n",
    "   compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:51:08.761636Z",
     "iopub.status.busy": "2024-03-13T13:51:08.761253Z",
     "iopub.status.idle": "2024-03-13T14:49:10.763801Z",
     "shell.execute_reply": "2024-03-13T14:49:10.762826Z",
     "shell.execute_reply.started": "2024-03-13T13:51:08.761608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 58:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loc Precision</th>\n",
       "      <th>Loc Recall</th>\n",
       "      <th>Loc F1</th>\n",
       "      <th>Loc Number</th>\n",
       "      <th>Org Precision</th>\n",
       "      <th>Org Recall</th>\n",
       "      <th>Org F1</th>\n",
       "      <th>Org Number</th>\n",
       "      <th>Per Precision</th>\n",
       "      <th>Per Recall</th>\n",
       "      <th>Per F1</th>\n",
       "      <th>Per Number</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>0.346491</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>0.539606</td>\n",
       "      <td>0.612674</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.482123</td>\n",
       "      <td>0.398222</td>\n",
       "      <td>0.436174</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.652571</td>\n",
       "      <td>0.575322</td>\n",
       "      <td>0.611516</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.615165</td>\n",
       "      <td>0.506690</td>\n",
       "      <td>0.555683</td>\n",
       "      <td>0.897141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.702113</td>\n",
       "      <td>0.598649</td>\n",
       "      <td>0.646266</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.503783</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.471024</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.706839</td>\n",
       "      <td>0.542771</td>\n",
       "      <td>0.614034</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.636578</td>\n",
       "      <td>0.529264</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.902196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.293586</td>\n",
       "      <td>0.672130</td>\n",
       "      <td>0.682659</td>\n",
       "      <td>0.677354</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.550400</td>\n",
       "      <td>0.471490</td>\n",
       "      <td>0.507898</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.665309</td>\n",
       "      <td>0.664743</td>\n",
       "      <td>0.665026</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.634863</td>\n",
       "      <td>0.608859</td>\n",
       "      <td>0.621589</td>\n",
       "      <td>0.910497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.279400</td>\n",
       "      <td>0.286097</td>\n",
       "      <td>0.697576</td>\n",
       "      <td>0.707138</td>\n",
       "      <td>0.702324</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.546242</td>\n",
       "      <td>0.515430</td>\n",
       "      <td>0.530389</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.719745</td>\n",
       "      <td>0.630867</td>\n",
       "      <td>0.672382</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.656256</td>\n",
       "      <td>0.619393</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>0.913340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.283199</td>\n",
       "      <td>0.740949</td>\n",
       "      <td>0.645256</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.598902</td>\n",
       "      <td>0.434703</td>\n",
       "      <td>0.503760</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.681157</td>\n",
       "      <td>0.655375</td>\n",
       "      <td>0.668017</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.679152</td>\n",
       "      <td>0.581346</td>\n",
       "      <td>0.626454</td>\n",
       "      <td>0.913304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.273426</td>\n",
       "      <td>0.719460</td>\n",
       "      <td>0.694311</td>\n",
       "      <td>0.706662</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.535803</td>\n",
       "      <td>0.551298</td>\n",
       "      <td>0.543440</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.690946</td>\n",
       "      <td>0.705526</td>\n",
       "      <td>0.698160</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.649238</td>\n",
       "      <td>0.652403</td>\n",
       "      <td>0.650817</td>\n",
       "      <td>0.915677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.269328</td>\n",
       "      <td>0.722036</td>\n",
       "      <td>0.716734</td>\n",
       "      <td>0.719375</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.588584</td>\n",
       "      <td>0.507868</td>\n",
       "      <td>0.545255</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.691003</td>\n",
       "      <td>0.709311</td>\n",
       "      <td>0.700037</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.672307</td>\n",
       "      <td>0.647299</td>\n",
       "      <td>0.659566</td>\n",
       "      <td>0.918582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.266063</td>\n",
       "      <td>0.674947</td>\n",
       "      <td>0.752864</td>\n",
       "      <td>0.711780</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.597890</td>\n",
       "      <td>0.521153</td>\n",
       "      <td>0.556890</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.743174</td>\n",
       "      <td>0.672218</td>\n",
       "      <td>0.705917</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.674774</td>\n",
       "      <td>0.650800</td>\n",
       "      <td>0.662570</td>\n",
       "      <td>0.919670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.257876</td>\n",
       "      <td>0.716366</td>\n",
       "      <td>0.732008</td>\n",
       "      <td>0.724103</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.562789</td>\n",
       "      <td>0.571531</td>\n",
       "      <td>0.567126</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.725420</td>\n",
       "      <td>0.714232</td>\n",
       "      <td>0.719783</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.669840</td>\n",
       "      <td>0.674486</td>\n",
       "      <td>0.672155</td>\n",
       "      <td>0.921668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.219600</td>\n",
       "      <td>0.250990</td>\n",
       "      <td>0.724527</td>\n",
       "      <td>0.742191</td>\n",
       "      <td>0.733253</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.593237</td>\n",
       "      <td>0.557531</td>\n",
       "      <td>0.574830</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.741360</td>\n",
       "      <td>0.704391</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.689562</td>\n",
       "      <td>0.670004</td>\n",
       "      <td>0.679642</td>\n",
       "      <td>0.922897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.256628</td>\n",
       "      <td>0.710708</td>\n",
       "      <td>0.755801</td>\n",
       "      <td>0.732561</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.592783</td>\n",
       "      <td>0.553955</td>\n",
       "      <td>0.572711</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.712537</td>\n",
       "      <td>0.721707</td>\n",
       "      <td>0.717093</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.676229</td>\n",
       "      <td>0.679393</td>\n",
       "      <td>0.677807</td>\n",
       "      <td>0.922246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.255390</td>\n",
       "      <td>0.740675</td>\n",
       "      <td>0.732987</td>\n",
       "      <td>0.736811</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.576695</td>\n",
       "      <td>0.567443</td>\n",
       "      <td>0.572032</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.723975</td>\n",
       "      <td>0.725208</td>\n",
       "      <td>0.724591</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.682772</td>\n",
       "      <td>0.677299</td>\n",
       "      <td>0.680024</td>\n",
       "      <td>0.922539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.256375</td>\n",
       "      <td>0.725620</td>\n",
       "      <td>0.742387</td>\n",
       "      <td>0.733908</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.591520</td>\n",
       "      <td>0.561721</td>\n",
       "      <td>0.576236</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.727614</td>\n",
       "      <td>0.715083</td>\n",
       "      <td>0.721294</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.684944</td>\n",
       "      <td>0.675107</td>\n",
       "      <td>0.679990</td>\n",
       "      <td>0.923157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.256834</td>\n",
       "      <td>0.721212</td>\n",
       "      <td>0.753060</td>\n",
       "      <td>0.736792</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.586482</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.571264</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.716632</td>\n",
       "      <td>0.726533</td>\n",
       "      <td>0.721549</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.678796</td>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.679927</td>\n",
       "      <td>0.923650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.164800</td>\n",
       "      <td>0.255738</td>\n",
       "      <td>0.737568</td>\n",
       "      <td>0.743562</td>\n",
       "      <td>0.740553</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.578472</td>\n",
       "      <td>0.569487</td>\n",
       "      <td>0.573944</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.728235</td>\n",
       "      <td>0.722653</td>\n",
       "      <td>0.725433</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.683960</td>\n",
       "      <td>0.680603</td>\n",
       "      <td>0.682277</td>\n",
       "      <td>0.923679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory model/upos/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:58:36.915565Z",
     "iopub.status.busy": "2024-03-13T14:58:36.915176Z",
     "iopub.status.idle": "2024-03-13T14:58:37.304339Z",
     "shell.execute_reply": "2024-03-13T14:58:37.303272Z",
     "shell.execute_reply.started": "2024-03-13T14:58:36.915535Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "trainer.save_model(\"model_indic_bert_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:58:39.343440Z",
     "iopub.status.busy": "2024-03-13T14:58:39.343024Z",
     "iopub.status.idle": "2024-03-13T14:58:40.701336Z",
     "shell.execute_reply": "2024-03-13T14:58:40.700127Z",
     "shell.execute_reply.started": "2024-03-13T14:58:39.343408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='directory.zip' target='_blank'>directory.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/directory.zip"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "def zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n",
    "    \"\"\"\n",
    "    zip all the files in a directory\n",
    "    \n",
    "    Parameters\n",
    "    ___\n",
    "    directory: str\n",
    "        directory needs to be zipped, defualt is current working directory\n",
    "        \n",
    "    file_name: str\n",
    "        the name of the zipped file (including .zip), default is 'directory.zip'\n",
    "        \n",
    "    Returns\n",
    "    ___\n",
    "    Creates a hyperlink, which can be used to download the zip file)\n",
    "    \"\"\"\n",
    "    os.chdir(directory)\n",
    "    zip_ref = zipfile.ZipFile(file_name, mode='w')\n",
    "    for folder, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file_name in file:\n",
    "                pass\n",
    "            else:\n",
    "                zip_ref.write(os.path.join(folder, file))\n",
    "\n",
    "    return FileLink(file_name)\n",
    "zip_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T14:58:54.536254Z",
     "iopub.status.busy": "2024-03-13T14:58:54.535873Z",
     "iopub.status.idle": "2024-03-13T15:01:05.577612Z",
     "shell.execute_reply": "2024-03-13T15:01:05.576474Z",
     "shell.execute_reply.started": "2024-03-13T14:58:54.536226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_LOC_f1             =     0.7406\n",
      "  eval_LOC_number         =      10213\n",
      "  eval_LOC_precision      =     0.7376\n",
      "  eval_LOC_recall         =     0.7436\n",
      "  eval_ORG_f1             =     0.5739\n",
      "  eval_ORG_number         =       9786\n",
      "  eval_ORG_precision      =     0.5785\n",
      "  eval_ORG_recall         =     0.5695\n",
      "  eval_PER_f1             =     0.7254\n",
      "  eval_PER_number         =      10568\n",
      "  eval_PER_precision      =     0.7282\n",
      "  eval_PER_recall         =     0.7227\n",
      "  eval_loss               =     0.2557\n",
      "  eval_overall_accuracy   =     0.9237\n",
      "  eval_overall_f1         =     0.6823\n",
      "  eval_overall_precision  =      0.684\n",
      "  eval_overall_recall     =     0.6806\n",
      "  eval_runtime            = 0:02:11.01\n",
      "  eval_samples_per_second =    102.738\n",
      "  eval_steps_per_second   =     12.846\n"
     ]
    }
   ],
   "source": [
    "# Evaluating MODel\n",
    "Final_metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"eval\", Final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:12:27.813616Z",
     "iopub.status.busy": "2024-03-13T15:12:27.812546Z",
     "iopub.status.idle": "2024-03-13T15:15:42.934341Z",
     "shell.execute_reply": "2024-03-13T15:15:42.933273Z",
     "shell.execute_reply.started": "2024-03-13T15:12:27.813573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  test_LOC_f1             =      0.832\n",
      "  test_LOC_number         =      14841\n",
      "  test_LOC_precision      =     0.8228\n",
      "  test_LOC_recall         =     0.8413\n",
      "  test_ORG_f1             =     0.7059\n",
      "  test_ORG_number         =      14082\n",
      "  test_ORG_precision      =     0.7151\n",
      "  test_ORG_recall         =      0.697\n",
      "  test_PER_f1             =     0.8359\n",
      "  test_PER_number         =      15614\n",
      "  test_PER_precision      =     0.8364\n",
      "  test_PER_recall         =     0.8354\n",
      "  test_loss               =     0.1506\n",
      "  test_overall_accuracy   =      0.955\n",
      "  test_overall_f1         =      0.794\n",
      "  test_overall_precision  =     0.7943\n",
      "  test_overall_recall     =     0.7936\n",
      "  test_runtime            = 0:03:15.09\n",
      "  test_samples_per_second =    102.516\n",
      "  test_steps_per_second   =     12.814\n",
      "\n",
      " Macro f1 score:: 0.791260325081025\n"
     ]
    }
   ],
   "source": [
    "# Testing on Training dataset\n",
    "predictions, labels, metrics = trainer.predict(tokenized_train_dataset)\n",
    "trainer.log_metrics(\"train\",metrics)\n",
    "\n",
    "sum_of_f1_scores=metrics['test_LOC_f1']+metrics['test_ORG_f1']+metrics['test_PER_f1']\n",
    "macro_f1=sum_of_f1_scores/3\n",
    "print('\\n Macro f1 score::',macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on 20% Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:17:50.994140Z",
     "iopub.status.busy": "2024-03-13T15:17:50.993259Z",
     "iopub.status.idle": "2024-03-13T15:17:51.749350Z",
     "shell.execute_reply": "2024-03-13T15:17:51.748308Z",
     "shell.execute_reply.started": "2024-03-13T15:17:50.994098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 867\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
    "lang = 'hi'\n",
    "test_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'test')\n",
    "# Test Dataset\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    ")\n",
    "print(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:17:55.132276Z",
     "iopub.status.busy": "2024-03-13T15:17:55.131862Z",
     "iopub.status.idle": "2024-03-13T15:18:03.604267Z",
     "shell.execute_reply": "2024-03-13T15:18:03.603131Z",
     "shell.execute_reply.started": "2024-03-13T15:17:55.132238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Test metrics *****\n",
      "  test_LOC_f1             =     0.7012\n",
      "  test_LOC_number         =        614\n",
      "  test_LOC_precision      =     0.7088\n",
      "  test_LOC_recall         =     0.6938\n",
      "  test_ORG_f1             =     0.6392\n",
      "  test_ORG_number         =        525\n",
      "  test_ORG_precision      =     0.6155\n",
      "  test_ORG_recall         =     0.6648\n",
      "  test_PER_f1             =     0.7462\n",
      "  test_PER_number         =        790\n",
      "  test_PER_precision      =     0.7443\n",
      "  test_PER_recall         =     0.7481\n",
      "  test_loss               =     0.2144\n",
      "  test_overall_accuracy   =     0.9343\n",
      "  test_overall_f1         =     0.7021\n",
      "  test_overall_precision  =     0.6962\n",
      "  test_overall_recall     =     0.7081\n",
      "  test_runtime            = 0:00:08.44\n",
      "  test_samples_per_second =    102.675\n",
      "  test_steps_per_second   =     12.908\n",
      "\n",
      " Macro f1 score:: 0.6955469427691648\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Model on test Data\n",
    "predictions, labels, metrics = trainer.predict(tokenized_test_dataset)\n",
    "trainer.log_metrics(\"Test\",metrics)\n",
    "\n",
    "sum_of_f1_scores=metrics['test_LOC_f1']+metrics['test_ORG_f1']+metrics['test_PER_f1']\n",
    "macro_f1=sum_of_f1_scores/3\n",
    "print('\\n Macro f1 score::',macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
