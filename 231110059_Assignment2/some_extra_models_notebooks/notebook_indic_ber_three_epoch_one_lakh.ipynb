{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install datasets\n!pip3 install sentencepiece\n!pip3 install seqeval\n!pip install transformers[torch]\n!pip install accelerate -U","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-10T19:34:29.396118Z","iopub.execute_input":"2024-03-10T19:34:29.396485Z","iopub.status.idle":"2024-03-10T19:35:30.709996Z","shell.execute_reply.started":"2024-03-10T19:34:29.396456Z","shell.execute_reply":"2024-03-10T19:35:30.708592Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.27.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import datasets","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:30.712573Z","iopub.execute_input":"2024-03-10T19:35:30.712911Z","iopub.status.idle":"2024-03-10T19:35:30.718083Z","shell.execute_reply.started":"2024-03-10T19:35:30.712872Z","shell.execute_reply":"2024-03-10T19:35:30.717056Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Let's download the Naampadam (Indic NER) dataset\nfrom datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n\nlang='hi'\n\ntrain_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'train[:100000]')\nvalidation_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'validation')\ntest_dataset = load_dataset('ai4bharat/naamapadam', lang , split = 'test')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:30.719346Z","iopub.execute_input":"2024-03-10T19:35:30.719625Z","iopub.status.idle":"2024-03-10T19:35:31.914354Z","shell.execute_reply.started":"2024-03-10T19:35:30.719600Z","shell.execute_reply":"2024-03-10T19:35:31.913458Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"features = train_dataset.features\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:31.917105Z","iopub.execute_input":"2024-03-10T19:35:31.917790Z","iopub.status.idle":"2024-03-10T19:35:31.922058Z","shell.execute_reply.started":"2024-03-10T19:35:31.917755Z","shell.execute_reply":"2024-03-10T19:35:31.921059Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n","output_type":"stream"}]},{"cell_type":"code","source":"text_column_name = \"tokens\"\nlabel_column_name = \"ner_tags\"\n\nlabel_list = features[label_column_name].feature.names\n\nlabel_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n\nprint(label_to_id)\n\nnum_labels = len(label_list)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:31.923318Z","iopub.execute_input":"2024-03-10T19:35:31.923577Z","iopub.status.idle":"2024-03-10T19:35:31.932857Z","shell.execute_reply.started":"2024-03-10T19:35:31.923554Z","shell.execute_reply":"2024-03-10T19:35:31.932056Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\nimport numpy as np\n\nconfig = AutoConfig.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels, finetuning_task='ner')\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\nmodel = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:31.934041Z","iopub.execute_input":"2024-03-10T19:35:31.934309Z","iopub.status.idle":"2024-03-10T19:35:34.640329Z","shell.execute_reply.started":"2024-03-10T19:35:31.934275Z","shell.execute_reply":"2024-03-10T19:35:34.639571Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize all texts and align the labels with them.\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[text_column_name],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=256,\n        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n        is_split_into_words=True,\n    )\n    # print(tokenized_inputs)\n    labels = []\n    for i, label in enumerate(examples[label_column_name]):\n        # print('=====')\n        # print('{} {}'.format(i,label)) #ak\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n            # ignored in the loss function.\n            if word_idx is None:\n                label_ids.append(-100)\n            # We set the label for the first token of each word.\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n            # the label_all_tokens flag.\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    # print(tokenized_inputs)\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:34.641625Z","iopub.execute_input":"2024-03-10T19:35:34.642460Z","iopub.status.idle":"2024-03-10T19:35:34.650767Z","shell.execute_reply.started":"2024-03-10T19:35:34.642414Z","shell.execute_reply":"2024-03-10T19:35:34.649724Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"correct_output = tokenize_and_align_labels(train_dataset[0:1])\ntokens = tokenizer.convert_ids_to_tokens(correct_output[\"input_ids\"][0])\nprint(tokens)\n\n# Now we have input ids and labels to pass to model","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:34.651923Z","iopub.execute_input":"2024-03-10T19:35:34.652212Z","iopub.status.idle":"2024-03-10T19:35:34.671946Z","shell.execute_reply.started":"2024-03-10T19:35:34.652189Z","shell.execute_reply":"2024-03-10T19:35:34.671118Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"['[CLS]', '▁सक', 'टर', '▁55', '/', '56', '▁क', '▁एसएचओ', '▁अर', 'वद', '▁कमर', '▁न', '▁बत', 'य', '▁क', '▁इस', '▁म', 'मल', '▁म', '▁आई', 'पस', '▁क', '▁धर', '▁376', '▁-', '▁ड', '▁(', '▁ग', 'गर', 'प', '▁)', '▁क', '▁तहत', '▁म', 'मल', '▁दर', 'ज', '▁कर', '▁लय', '▁ग', 'य', '▁ह', '▁।', '[SEP]', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","output_type":"stream"}]},{"cell_type":"code","source":"for token,label in zip(tokenizer.convert_ids_to_tokens(correct_output[\"input_ids\"][0]) , correct_output[\"labels\"][0]):\n  print(f\"{token:_<40}{label}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:34.672915Z","iopub.execute_input":"2024-03-10T19:35:34.673207Z","iopub.status.idle":"2024-03-10T19:35:34.681548Z","shell.execute_reply.started":"2024-03-10T19:35:34.673175Z","shell.execute_reply":"2024-03-10T19:35:34.680616Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[CLS]___________________________________-100\n▁सक_____________________________________0\nटर______________________________________-100\n▁55_____________________________________0\n/_______________________________________-100\n56______________________________________-100\n▁क______________________________________0\n▁एसएचओ__________________________________0\n▁अर_____________________________________1\nवद______________________________________-100\n▁कमर____________________________________2\n▁न______________________________________0\n▁बत_____________________________________0\nय_______________________________________-100\n▁क______________________________________0\n▁इस_____________________________________0\n▁म______________________________________0\nमल______________________________________-100\n▁म______________________________________0\n▁आई_____________________________________0\nपस______________________________________-100\n▁क______________________________________0\n▁धर_____________________________________0\n▁376____________________________________0\n▁-______________________________________0\n▁ड______________________________________0\n▁(______________________________________0\n▁ग______________________________________0\nगर______________________________________-100\nप_______________________________________-100\n▁)______________________________________0\n▁क______________________________________0\n▁तहत____________________________________0\n▁म______________________________________0\nमल______________________________________-100\n▁दर_____________________________________0\nज_______________________________________-100\n▁कर_____________________________________0\n▁लय_____________________________________0\n▁ग______________________________________0\nय_______________________________________-100\n▁ह______________________________________0\n▁।______________________________________0\n[SEP]___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n<pad>___________________________________-100\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_train_dataset = train_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n)\nprint(tokenized_train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:35:34.685391Z","iopub.execute_input":"2024-03-10T19:35:34.685731Z","iopub.status.idle":"2024-03-10T19:36:18.349564Z","shell.execute_reply.started":"2024-03-10T19:35:34.685707Z","shell.execute_reply":"2024-03-10T19:36:18.348722Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c0f5f50f66f42beb41b6db9e504de23"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 100000\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"# Problem is fixed now!!\nprint(len(tokenized_train_dataset[0]['ner_tags']))\nprint(len(tokenized_train_dataset[0]['labels']))\nprint(len(tokenized_train_dataset[0]['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:36:18.350684Z","iopub.execute_input":"2024-03-10T19:36:18.350981Z","iopub.status.idle":"2024-03-10T19:36:18.359908Z","shell.execute_reply.started":"2024-03-10T19:36:18.350955Z","shell.execute_reply":"2024-03-10T19:36:18.358817Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"30\n256\n256\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test Dataset\ntokenized_test_dataset = test_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n)\nprint(tokenized_test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:36:18.361267Z","iopub.execute_input":"2024-03-10T19:36:18.361704Z","iopub.status.idle":"2024-03-10T19:36:18.984698Z","shell.execute_reply.started":"2024-03-10T19:36:18.361668Z","shell.execute_reply":"2024-03-10T19:36:18.983815Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b0db515691b4a4b87f1214bee8df490"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 867\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"# Validation DataSet\ntokenized_validation_dataset = validation_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n)\nprint(tokenized_validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:36:18.985899Z","iopub.execute_input":"2024-03-10T19:36:18.986263Z","iopub.status.idle":"2024-03-10T19:36:25.032214Z","shell.execute_reply.started":"2024-03-10T19:36:18.986229Z","shell.execute_reply":"2024-03-10T19:36:25.031233Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/14 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"331e7ed476984b6d8af514e4f2c8848a"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 13460\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data Collator\ndata_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:36:25.033373Z","iopub.execute_input":"2024-03-10T19:36:25.033693Z","iopub.status.idle":"2024-03-10T19:36:25.357336Z","shell.execute_reply.started":"2024-03-10T19:36:25.033666Z","shell.execute_reply":"2024-03-10T19:36:25.356225Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Metric to see how my model is performing For NER we use seqeval\nmetric = datasets.load_metric(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:36:25.358950Z","iopub.execute_input":"2024-03-10T19:36:25.359320Z","iopub.status.idle":"2024-03-10T19:36:25.715811Z","shell.execute_reply.started":"2024-03-10T19:36:25.359291Z","shell.execute_reply":"2024-03-10T19:36:25.715025Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Seeing the working of seqeval\nexample_text = train_dataset[0]\nlabel_list = train_dataset.features[\"ner_tags\"].feature.names\nlabel_list\n\nlabels = [label_list[i] for i in example_text[\"ner_tags\"]]\nprint(labels)\n\nmetric.compute(predictions=[labels] , references=[labels])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:36:25.717058Z","iopub.execute_input":"2024-03-10T19:36:25.717408Z","iopub.status.idle":"2024-03-10T19:36:25.733997Z","shell.execute_reply.started":"2024-03-10T19:36:25.717373Z","shell.execute_reply":"2024-03-10T19:36:25.732922Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"{'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 1.0,\n 'overall_f1': 1.0,\n 'overall_accuracy': 1.0}"},"metadata":{}}]},{"cell_type":"code","source":"# Metrics\nmetric = load_metric(\"seqeval\")\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n          \"precision\": results[\"overall_precision\"],\n          \"recall\": results[\"overall_recall\"],\n          \"f1\": results[\"overall_f1\"],\n          \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:36:25.735644Z","iopub.execute_input":"2024-03-10T19:36:25.735986Z","iopub.status.idle":"2024-03-10T19:36:25.951309Z","shell.execute_reply.started":"2024-03-10T19:36:25.735953Z","shell.execute_reply":"2024-03-10T19:36:25.950593Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Define Training Args\nargs = TrainingArguments(\n    output_dir=f\"model/upos\",\n    overwrite_output_dir=True,\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=10,\n    per_device_eval_batch_size=10,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_total_limit=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:58:04.648612Z","iopub.execute_input":"2024-03-10T19:58:04.649362Z","iopub.status.idle":"2024-03-10T19:58:04.658947Z","shell.execute_reply.started":"2024-03-10T19:58:04.649329Z","shell.execute_reply":"2024-03-10T19:58:04.657835Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n   model,\n   args,\n   train_dataset=tokenized_train_dataset,\n   eval_dataset=tokenized_validation_dataset,\n   data_collator=data_collator,\n   tokenizer=tokenizer,\n   compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:58:04.943317Z","iopub.execute_input":"2024-03-10T19:58:04.943666Z","iopub.status.idle":"2024-03-10T19:58:04.955838Z","shell.execute_reply.started":"2024-03-10T19:58:04.943640Z","shell.execute_reply":"2024-03-10T19:58:04.954834Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"train_result = trainer.train()\nmetrics = train_result.metrics","metadata":{"execution":{"iopub.status.busy":"2024-03-10T19:58:05.334473Z","iopub.execute_input":"2024-03-10T19:58:05.334811Z","iopub.status.idle":"2024-03-10T21:55:26.721164Z","shell.execute_reply.started":"2024-03-10T19:58:05.334784Z","shell.execute_reply":"2024-03-10T21:55:26.720069Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15000/15000 1:57:20, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.224500</td>\n      <td>0.223765</td>\n      <td>0.714594</td>\n      <td>0.703373</td>\n      <td>0.708939</td>\n      <td>0.930022</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.193700</td>\n      <td>0.219003</td>\n      <td>0.718879</td>\n      <td>0.713187</td>\n      <td>0.716022</td>\n      <td>0.931389</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.177300</td>\n      <td>0.220512</td>\n      <td>0.716457</td>\n      <td>0.717113</td>\n      <td>0.716785</td>\n      <td>0.931593</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nCheckpoint destination directory model/upos/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=15000, training_loss=0.19966048278808593, metrics={'train_runtime': 7040.8301, 'train_samples_per_second': 42.609, 'train_steps_per_second': 2.13, 'total_flos': 3314342246400000.0, 'train_loss': 0.19966048278808593, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save Model\ntrainer.save_model(\"model_indic_bert_3Epoch_lakh\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:58:21.182574Z","iopub.execute_input":"2024-03-10T21:58:21.182993Z","iopub.status.idle":"2024-03-10T21:58:21.553075Z","shell.execute_reply.started":"2024-03-10T21:58:21.182961Z","shell.execute_reply":"2024-03-10T21:58:21.552037Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\nfrom IPython.display import FileLink\n\ndef zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n    \"\"\"\n    zip all the files in a directory\n    \n    Parameters\n    ___\n    directory: str\n        directory needs to be zipped, defualt is current working directory\n        \n    file_name: str\n        the name of the zipped file (including .zip), default is 'directory.zip'\n        \n    Returns\n    ___\n    Creates a hyperlink, which can be used to download the zip file)\n    \"\"\"\n    os.chdir(directory)\n    zip_ref = zipfile.ZipFile(file_name, mode='w')\n    for folder, _, files in os.walk(directory):\n        for file in files:\n            if file_name in file:\n                pass\n            else:\n                zip_ref.write(os.path.join(folder, file))\n\n    return FileLink(file_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:58:30.192676Z","iopub.execute_input":"2024-03-10T21:58:30.193419Z","iopub.status.idle":"2024-03-10T21:58:30.202562Z","shell.execute_reply.started":"2024-03-10T21:58:30.193380Z","shell.execute_reply":"2024-03-10T21:58:30.200911Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"zip_dir()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T21:58:38.080737Z","iopub.execute_input":"2024-03-10T21:58:38.081453Z","iopub.status.idle":"2024-03-10T21:58:39.444405Z","shell.execute_reply.started":"2024-03-10T21:58:38.081421Z","shell.execute_reply":"2024-03-10T21:58:39.443330Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/directory.zip","text/html":"<a href='directory.zip' target='_blank'>directory.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"metrics=trainer.evaluate()\nprint(metrics)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T22:00:41.039198Z","iopub.execute_input":"2024-03-10T22:00:41.039662Z","iopub.status.idle":"2024-03-10T22:02:47.739411Z","shell.execute_reply.started":"2024-03-10T22:00:41.039625Z","shell.execute_reply":"2024-03-10T22:02:47.738208Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"{'eval_loss': 0.2205115109682083, 'eval_precision': 0.7164569374080733, 'eval_recall': 0.7171132266823699, 'eval_f1': 0.7167849318204114, 'eval_accuracy': 0.9315930616993446, 'eval_runtime': 126.6802, 'eval_samples_per_second': 106.252, 'eval_steps_per_second': 5.313, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}