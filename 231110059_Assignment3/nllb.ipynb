{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T00:47:55.847744Z",
     "iopub.status.busy": "2024-04-15T00:47:55.847151Z",
     "iopub.status.idle": "2024-04-15T00:48:11.813686Z",
     "shell.execute_reply": "2024-04-15T00:48:11.812575Z",
     "shell.execute_reply.started": "2024-04-15T00:47:55.847717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.17.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Downloading openai-1.17.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "Successfully installed openai-1.17.1\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement IndicTransTokenizer (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for IndicTransTokenizer\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install IndicTransTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T00:58:49.791043Z",
     "iopub.status.busy": "2024-04-16T00:58:49.790671Z",
     "iopub.status.idle": "2024-04-16T00:58:49.796003Z",
     "shell.execute_reply": "2024-04-16T00:58:49.794907Z",
     "shell.execute_reply.started": "2024-04-16T00:58:49.791016Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-16T00:27:13.967252Z",
     "iopub.status.busy": "2024-04-16T00:27:13.966869Z",
     "iopub.status.idle": "2024-04-16T00:27:49.765434Z",
     "shell.execute_reply": "2024-04-16T00:27:49.764464Z",
     "shell.execute_reply.started": "2024-04-16T00:27:13.967223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c167e3f9d70b45b996467acb731f8367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb387fd4f7642e6a8c2c3fc9a89f138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8c9c4f7f3b465a96ef4c23561cbbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7decc7b37fe450fadda99217a8629dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93904060e87a4acba174bdb6014a2d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31048204e7dd4ddaada8ce17c2f88d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0745c5ba5146f3bed28e146821940f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the `lang_code_to_id` attribute is deprecated. The logic is natively handled in the `tokenizer.adder_tokens_decoder` this attribute will be removed in `transformers` v4.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "યુએન ચીફનું કહેવું છે કે સીરિયામાં કોઈ લશ્કરી ઉકેલ નથી\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "l = []\n",
    "article = \"UN Chief says there is no military solution in Syria\"\n",
    "inputs = tokenizer(article, return_tensors=\"pt\")\n",
    "\n",
    "translated_tokens = model.generate(\n",
    "    **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"guj_Gujr\"], max_length=30\n",
    ")\n",
    "l.append(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0])\n",
    "print(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T00:48:34.558131Z",
     "iopub.status.busy": "2024-04-15T00:48:34.557186Z",
     "iopub.status.idle": "2024-04-15T00:48:34.564186Z",
     "shell.execute_reply": "2024-04-15T00:48:34.563174Z",
     "shell.execute_reply.started": "2024-04-15T00:48:34.558060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported language codes: dict_keys(['ace_Arab', 'ace_Latn', 'acm_Arab', 'acq_Arab', 'aeb_Arab', 'afr_Latn', 'ajp_Arab', 'aka_Latn', 'amh_Ethi', 'apc_Arab', 'arb_Arab', 'ars_Arab', 'ary_Arab', 'arz_Arab', 'asm_Beng', 'ast_Latn', 'awa_Deva', 'ayr_Latn', 'azb_Arab', 'azj_Latn', 'bak_Cyrl', 'bam_Latn', 'ban_Latn', 'bel_Cyrl', 'bem_Latn', 'ben_Beng', 'bho_Deva', 'bjn_Arab', 'bjn_Latn', 'bod_Tibt', 'bos_Latn', 'bug_Latn', 'bul_Cyrl', 'cat_Latn', 'ceb_Latn', 'ces_Latn', 'cjk_Latn', 'ckb_Arab', 'crh_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'dik_Latn', 'dyu_Latn', 'dzo_Tibt', 'ell_Grek', 'eng_Latn', 'epo_Latn', 'est_Latn', 'eus_Latn', 'ewe_Latn', 'fao_Latn', 'pes_Arab', 'fij_Latn', 'fin_Latn', 'fon_Latn', 'fra_Latn', 'fur_Latn', 'fuv_Latn', 'gla_Latn', 'gle_Latn', 'glg_Latn', 'grn_Latn', 'guj_Gujr', 'hat_Latn', 'hau_Latn', 'heb_Hebr', 'hin_Deva', 'hne_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Armn', 'ibo_Latn', 'ilo_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jav_Latn', 'jpn_Jpan', 'kab_Latn', 'kac_Latn', 'kam_Latn', 'kan_Knda', 'kas_Arab', 'kas_Deva', 'kat_Geor', 'knc_Arab', 'knc_Latn', 'kaz_Cyrl', 'kbp_Latn', 'kea_Latn', 'khm_Khmr', 'kik_Latn', 'kin_Latn', 'kir_Cyrl', 'kmb_Latn', 'kon_Latn', 'kor_Hang', 'kmr_Latn', 'lao_Laoo', 'lvs_Latn', 'lij_Latn', 'lim_Latn', 'lin_Latn', 'lit_Latn', 'lmo_Latn', 'ltg_Latn', 'ltz_Latn', 'lua_Latn', 'lug_Latn', 'luo_Latn', 'lus_Latn', 'mag_Deva', 'mai_Deva', 'mal_Mlym', 'mar_Deva', 'min_Latn', 'mkd_Cyrl', 'plt_Latn', 'mlt_Latn', 'mni_Beng', 'khk_Cyrl', 'mos_Latn', 'mri_Latn', 'zsm_Latn', 'mya_Mymr', 'nld_Latn', 'nno_Latn', 'nob_Latn', 'npi_Deva', 'nso_Latn', 'nus_Latn', 'nya_Latn', 'oci_Latn', 'gaz_Latn', 'ory_Orya', 'pag_Latn', 'pan_Guru', 'pap_Latn', 'pol_Latn', 'por_Latn', 'prs_Arab', 'pbt_Arab', 'quy_Latn', 'ron_Latn', 'run_Latn', 'rus_Cyrl', 'sag_Latn', 'san_Deva', 'sat_Beng', 'scn_Latn', 'shn_Mymr', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'smo_Latn', 'sna_Latn', 'snd_Arab', 'som_Latn', 'sot_Latn', 'spa_Latn', 'als_Latn', 'srd_Latn', 'srp_Cyrl', 'ssw_Latn', 'sun_Latn', 'swe_Latn', 'swh_Latn', 'szl_Latn', 'tam_Taml', 'tat_Cyrl', 'tel_Telu', 'tgk_Cyrl', 'tgl_Latn', 'tha_Thai', 'tir_Ethi', 'taq_Latn', 'taq_Tfng', 'tpi_Latn', 'tsn_Latn', 'tso_Latn', 'tuk_Latn', 'tum_Latn', 'tur_Latn', 'twi_Latn', 'tzm_Tfng', 'uig_Arab', 'ukr_Cyrl', 'umb_Latn', 'urd_Arab', 'uzn_Latn', 'vec_Latn', 'vie_Latn', 'war_Latn', 'wol_Latn', 'xho_Latn', 'ydd_Hebr', 'yor_Latn', 'yue_Hant', 'zho_Hans', 'zho_Hant', 'zul_Latn'])\n"
     ]
    }
   ],
   "source": [
    "# Finding Supporting Language\n",
    "print(\"Supported language codes:\", tokenizer.lang_code_to_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T00:48:34.567127Z",
     "iopub.status.busy": "2024-04-15T00:48:34.566463Z",
     "iopub.status.idle": "2024-04-15T00:48:36.940872Z",
     "shell.execute_reply": "2024-04-15T00:48:36.939867Z",
     "shell.execute_reply.started": "2024-04-15T00:48:34.567092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He added that their efforts have ensured that Indian Passport is respected everywhere.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def select_and_save_random_sentences(english_file, hindi_file, gujarati_file, num_sentences=1000):\n",
    "\n",
    "    # Read all sentences from each file\n",
    "    with open(english_file, \"r\") as f:\n",
    "        english_sentences = f.readlines()\n",
    "    with open(hindi_file, \"r\") as f:\n",
    "        hindi_sentences = f.readlines()\n",
    "    with open(gujarati_file, \"r\") as f:\n",
    "        gujarati_sentences = f.readlines()\n",
    "\n",
    "  # Ensure all files have the same number of sentences\n",
    "    if len(english_sentences) != len(hindi_sentences) or len(english_sentences) != len(gujarati_sentences):\n",
    "        raise ValueError(\"All files must have the same number of sentences\")\n",
    "\n",
    "  # Select random sentences (use set to avoid duplicates)\n",
    "    selected_indices = random.sample(range(len(english_sentences)), num_sentences)\n",
    "\n",
    "  # Create lists to store selected sentences with newlines\n",
    "    selected_english = []\n",
    "    selected_hindi = []\n",
    "    selected_gujarati = []\n",
    "\n",
    "  # Extract selected sentences from each list and add newlines\n",
    "    for index in selected_indices:\n",
    "        selected_english.append(english_sentences[index].strip())\n",
    "        selected_hindi.append(hindi_sentences[index].strip())\n",
    "        selected_gujarati.append(gujarati_sentences[index].strip())\n",
    "    return(selected_english, selected_hindi, selected_gujarati)\n",
    "    print(f\"Successfully selected and saved {num_sentences} random sentences from each file (each sentence on a new line).\")\n",
    "\n",
    "# Replace with your actual file paths\n",
    "english_file = \"/kaggle/input/testing/test.en\"\n",
    "gujarati_file = \"/kaggle/input/testing/test.gu\"\n",
    "hindi_file = \"/kaggle/input/testing/test.hi\"\n",
    "\n",
    "en, hi, gu = select_and_save_random_sentences(english_file, hindi_file, gujarati_file)\n",
    "print(en[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T00:50:51.255655Z",
     "iopub.status.busy": "2024-04-15T00:50:51.254900Z",
     "iopub.status.idle": "2024-04-15T00:50:51.266844Z",
     "shell.execute_reply": "2024-04-15T00:50:51.266023Z",
     "shell.execute_reply.started": "2024-04-15T00:50:51.255625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He added that their efforts have ensured that Indian Passport is respected everywhere.\n"
     ]
    }
   ],
   "source": [
    "# Save English sentences\n",
    "with open('english_sentences.txt', 'w', encoding='utf-8') as en_file:\n",
    "    for sentence in en:\n",
    "        en_file.write(sentence + '\\n')\n",
    "\n",
    "# Save Hindi sentences\n",
    "with open('hindi_sentences.txt', 'w', encoding='utf-8') as hi_file:\n",
    "    for sentence in hi:\n",
    "        hi_file.write(sentence + '\\n')\n",
    "\n",
    "# Save Gujarati sentences\n",
    "with open('gujarati_sentences.txt', 'w', encoding='utf-8') as gu_file:\n",
    "    for sentence in gu:\n",
    "        gu_file.write(sentence + '\\n')\n",
    "\n",
    "# Print a sentence from English\n",
    "print(en[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T00:29:15.260908Z",
     "iopub.status.busy": "2024-04-16T00:29:15.259905Z",
     "iopub.status.idle": "2024-04-16T00:29:15.364074Z",
     "shell.execute_reply": "2024-04-16T00:29:15.363136Z",
     "shell.execute_reply.started": "2024-04-16T00:29:15.260874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: In Karnataka, especially in far-off, remote places, thousands of women availed of her services.\n",
      "Hindi: उन्होंने कर्नाटक में, विशेषकर वहाँ के दुर्गम इलाकों में हजारों माताओं-बहनों को अपनी सेवायें दीं।\n",
      "Gujarati: તેમણે કર્ણાટકમાં, ખાસ કરીને, ત્યાંના દુર્ગમ વિસ્તારોમાં હજારો માતાઓ-બહેનોને પોતાની સેવા આપી.\n"
     ]
    }
   ],
   "source": [
    "# Load These sentences\n",
    "def load_sentences(file_path):\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            sentences.append(line.strip())  # Remove leading/trailing whitespace\n",
    "    return sentences\n",
    "\n",
    "# Load English sentences\n",
    "en_sentences = load_sentences('/kaggle/input/random-sentence/english_sentences.txt')\n",
    "\n",
    "# Load Hindi sentences\n",
    "hi_sentences = load_sentences('/kaggle/input/random-sentence/hindi_sentences.txt')\n",
    "\n",
    "# Load Gujarati sentences\n",
    "gu_sentences = load_sentences('/kaggle/input/random-sentence/gujarati_sentences.txt')\n",
    "\n",
    "# Print a sentence from each language as an example\n",
    "print(\"English:\", en_sentences[0])\n",
    "print(\"Hindi:\", hi_sentences[0])\n",
    "print(\"Gujarati:\", gu_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T00:41:56.460994Z",
     "iopub.status.busy": "2024-04-16T00:41:56.460365Z",
     "iopub.status.idle": "2024-04-16T00:41:56.465032Z",
     "shell.execute_reply": "2024-04-16T00:41:56.464067Z",
     "shell.execute_reply.started": "2024-04-16T00:41:56.460962Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T01:02:06.249349Z",
     "iopub.status.busy": "2024-04-16T01:02:06.248891Z",
     "iopub.status.idle": "2024-04-16T01:02:06.255830Z",
     "shell.execute_reply": "2024-04-16T01:02:06.254902Z",
     "shell.execute_reply.started": "2024-04-16T01:02:06.249316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Translating one language to another\n",
    "def translate(model,tokenizer,lang, l):\n",
    "  translated_sentence = []\n",
    " \n",
    "  for i in range(len(l)):\n",
    "    inputs = tokenizer(l[i], return_tensors=\"pt\").to(device)\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[lang], max_length=30\n",
    "    )\n",
    "    translated_sentence.append(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0])\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T00:58:24.165020Z",
     "iopub.status.busy": "2024-04-16T00:58:24.164631Z",
     "iopub.status.idle": "2024-04-16T00:58:24.169449Z",
     "shell.execute_reply": "2024-04-16T00:58:24.168330Z",
     "shell.execute_reply.started": "2024-04-16T00:58:24.164988Z"
    }
   },
   "outputs": [],
   "source": [
    "hin = \"hin_Deva\"\n",
    "eng = \"eng_Latn\"\n",
    "guj = \"guj_Gujr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distilled model of NLLB-200 with 600M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T00:59:15.617284Z",
     "iopub.status.busy": "2024-04-16T00:59:15.616877Z",
     "iopub.status.idle": "2024-04-16T00:59:18.812503Z",
     "shell.execute_reply": "2024-04-16T00:59:18.811546Z",
     "shell.execute_reply.started": "2024-04-16T00:59:15.617250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2M100ForConditionalGeneration(\n",
       "  (model): M2M100Model(\n",
       "    (shared): Embedding(256206, 1024, padding_idx=1)\n",
       "    (encoder): M2M100Encoder(\n",
       "      (embed_tokens): Embedding(256206, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): M2M100Decoder(\n",
       "      (embed_tokens): Embedding(256206, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=256206, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "device=torch.device('cuda',0)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T11:34:06.835849Z",
     "iopub.status.busy": "2024-04-15T11:34:06.835488Z",
     "iopub.status.idle": "2024-04-15T12:14:11.469043Z",
     "shell.execute_reply": "2024-04-15T12:14:11.468024Z",
     "shell.execute_reply.started": "2024-04-15T11:34:06.835822Z"
    }
   },
   "outputs": [],
   "source": [
    "en_hi = translate(model,tokenizer,hin, en_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T12:24:09.451403Z",
     "iopub.status.busy": "2024-04-15T12:24:09.450959Z",
     "iopub.status.idle": "2024-04-15T12:24:09.463317Z",
     "shell.execute_reply": "2024-04-15T12:24:09.462244Z",
     "shell.execute_reply.started": "2024-04-15T12:24:09.451344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='translated_en_hi.txt' target='_blank'>translated_en_hi.txt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/translated_en_hi.txt"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save output to a file\n",
    "output_file = \"translated_en_hi.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(en_hi))\n",
    "# Download file\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'translated_en_hi.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T01:02:10.012376Z",
     "iopub.status.busy": "2024-04-16T01:02:10.011398Z",
     "iopub.status.idle": "2024-04-16T01:09:48.899661Z",
     "shell.execute_reply": "2024-04-16T01:09:48.898578Z",
     "shell.execute_reply.started": "2024-04-16T01:02:10.012337Z"
    }
   },
   "outputs": [],
   "source": [
    "hi_en = translate(model,tokenizer,eng, hi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T01:20:32.739732Z",
     "iopub.status.busy": "2024-04-16T01:20:32.739321Z",
     "iopub.status.idle": "2024-04-16T01:20:32.747582Z",
     "shell.execute_reply": "2024-04-16T01:20:32.746716Z",
     "shell.execute_reply.started": "2024-04-16T01:20:32.739702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='translated_hi_en.txt' target='_blank'>translated_hi_en.txt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/translated_hi_en.txt"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save output to a file\n",
    "output_file = \"translated_hi_en.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(hi_en))\n",
    "# Download file\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'translated_hi_en.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi to Gujrati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T01:22:13.286055Z",
     "iopub.status.busy": "2024-04-16T01:22:13.285296Z",
     "iopub.status.idle": "2024-04-16T01:30:25.438081Z",
     "shell.execute_reply": "2024-04-16T01:30:25.437214Z",
     "shell.execute_reply.started": "2024-04-16T01:22:13.286024Z"
    }
   },
   "outputs": [],
   "source": [
    "hi_gu = translate(model,tokenizer,guj, hi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T01:30:25.440410Z",
     "iopub.status.busy": "2024-04-16T01:30:25.439755Z",
     "iopub.status.idle": "2024-04-16T01:30:25.448432Z",
     "shell.execute_reply": "2024-04-16T01:30:25.447569Z",
     "shell.execute_reply.started": "2024-04-16T01:30:25.440369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='translated_hi_gu.txt' target='_blank'>translated_hi_gu.txt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/translated_hi_gu.txt"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save output to a file\n",
    "output_file = \"translated_hi_gu.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(hi_gu))\n",
    "# Download file\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'translated_hi_gu.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gujrati to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T01:32:53.668345Z",
     "iopub.status.busy": "2024-04-16T01:32:53.667959Z",
     "iopub.status.idle": "2024-04-16T01:41:09.971799Z",
     "shell.execute_reply": "2024-04-16T01:41:09.970975Z",
     "shell.execute_reply.started": "2024-04-16T01:32:53.668315Z"
    }
   },
   "outputs": [],
   "source": [
    "gu_hi = translate(model,tokenizer,hin, gu_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T01:41:09.973633Z",
     "iopub.status.busy": "2024-04-16T01:41:09.973354Z",
     "iopub.status.idle": "2024-04-16T01:41:09.982507Z",
     "shell.execute_reply": "2024-04-16T01:41:09.981633Z",
     "shell.execute_reply.started": "2024-04-16T01:41:09.973609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='translated_gu_hi.txt' target='_blank'>translated_gu_hi.txt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/translated_gu_hi.txt"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save output to a file\n",
    "output_file = \"translated_gu_hi.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(gu_hi))\n",
    "# Download file\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'translated_gu_hi.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T20:09:36.303135Z",
     "iopub.status.busy": "2024-04-14T20:09:36.302721Z",
     "iopub.status.idle": "2024-04-14T20:09:36.308231Z",
     "shell.execute_reply": "2024-04-14T20:09:36.307308Z",
     "shell.execute_reply.started": "2024-04-14T20:09:36.303104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(en_hi))\n",
    "print(len(hi))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4797127,
     "sourceId": 8118874,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4801380,
     "sourceId": 8124760,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
