{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndicTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:35:33.690818Z",
     "iopub.status.busy": "2024-04-16T11:35:33.690520Z",
     "iopub.status.idle": "2024-04-16T11:35:33.701238Z",
     "shell.execute_reply": "2024-04-16T11:35:33.700439Z",
     "shell.execute_reply.started": "2024-04-16T11:35:33.690792Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:36:02.814292Z",
     "iopub.status.busy": "2024-04-16T11:36:02.813919Z",
     "iopub.status.idle": "2024-04-16T11:36:54.351678Z",
     "shell.execute_reply": "2024-04-16T11:36:54.350481Z",
     "shell.execute_reply.started": "2024-04-16T11:36:02.814260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "Cloning into 'IndicTransTokenizer'...\n",
      "remote: Enumerating objects: 123, done.\u001b[K\n",
      "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
      "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
      "remote: Total 123 (delta 52), reused 94 (delta 31), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (123/123), 3.85 MiB | 16.31 MiB/s, done.\n",
      "Resolving deltas: 100% (52/52), done.\n",
      "/kaggle/working/IndicTransTokenizer\n",
      "Obtaining file:///kaggle/working/IndicTransTokenizer\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library (from IndicTransTokenizer==0.1.3)\n",
      "  Cloning https://github.com/VarunGumma/indic_nlp_library to /tmp/pip-install-m4lw8qgz/indic-nlp-library-it2_7b013b4945ed48afb9c2d71e8f185d6c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/VarunGumma/indic_nlp_library /tmp/pip-install-m4lw8qgz/indic-nlp-library-it2_7b013b4945ed48afb9c2d71e8f185d6c\n",
      "  Resolved https://github.com/VarunGumma/indic_nlp_library to commit 09d30a15286cc252a12682e5450c807379717eaf\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setuptools==68.2.2 (from IndicTransTokenizer==0.1.3)\n",
      "  Downloading setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (2.1.2)\n",
      "Collecting sacremoses (from IndicTransTokenizer==0.1.3)\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (0.2.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (4.39.3)\n",
      "Collecting sacrebleu==2.3.1 (from IndicTransTokenizer==0.1.3)\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m851.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (1.26.4)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (5.2.1)\n",
      "Collecting sphinx-argparse (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: sphinx_rtd_theme in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (0.2.4)\n",
      "Collecting morfessor (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.1.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (4.66.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->IndicTransTokenizer==0.1.3) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->IndicTransTokenizer==0.1.3) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (2024.2.2)\n",
      "Collecting sphinx>=1.2.0 (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinx-7.2.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->IndicTransTokenizer==0.1.3) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (1.16.0)\n",
      "Collecting sphinxcontrib-applehelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-devhelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-jsmath (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting sphinxcontrib-qthelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.17.2)\n",
      "Requirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (0.20.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.14.0)\n",
      "Collecting alabaster<0.8,>=0.7 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting imagesize>=1.3 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading sphinx-7.2.6-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alabaster-0.7.16-py3-none-any.whl (13 kB)\n",
      "Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: indic-nlp-library-IT2\n",
      "  Building wheel for indic-nlp-library-IT2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for indic-nlp-library-IT2: filename=indic_nlp_library_IT2-0.0.2-py3-none-any.whl size=49537 sha256=d4c1d52038cf7609515fd995f30fcd729a70603c47f867c6b742fefddc663249\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7gx647nb/wheels/e9/72/fa/bd9f19a3f2bacb50efcaf28b7ab89fe7ca539e35b75334befc\n",
      "Successfully built indic-nlp-library-IT2\n",
      "Installing collected packages: morfessor, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, setuptools, sacremoses, portalocker, imagesize, alabaster, sphinx, sacrebleu, sphinx-argparse, indic-nlp-library-IT2, IndicTransTokenizer\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.0.3\n",
      "    Uninstalling setuptools-69.0.3:\n",
      "      Successfully uninstalled setuptools-69.0.3\n",
      "  Running setup.py develop for IndicTransTokenizer\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed IndicTransTokenizer-0.1.3 alabaster-0.7.16 imagesize-1.4.1 indic-nlp-library-IT2-0.0.2 morfessor-2.0.6 portalocker-2.8.2 sacrebleu-2.3.1 sacremoses-0.1.1 setuptools-68.2.2 sphinx-7.2.6 sphinx-argparse-0.4.0 sphinxcontrib-applehelp-1.0.8 sphinxcontrib-devhelp-1.0.6 sphinxcontrib-htmlhelp-2.0.5 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.7 sphinxcontrib-serializinghtml-1.1.10\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/\n",
    "!git clone https://github.com/VarunGumma/IndicTransTokenizer\n",
    "%cd /kaggle/working/IndicTransTokenizer\n",
    "!pip install --editable ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:36:54.354154Z",
     "iopub.status.busy": "2024-04-16T11:36:54.353825Z",
     "iopub.status.idle": "2024-04-16T11:37:05.697878Z",
     "shell.execute_reply": "2024-04-16T11:37:05.696775Z",
     "shell.execute_reply.started": "2024-04-16T11:36:54.354124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from IndicTransTokenizer import IndicProcessor, IndicTransTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:37:05.699536Z",
     "iopub.status.busy": "2024-04-16T11:37:05.699101Z",
     "iopub.status.idle": "2024-04-16T11:37:06.663934Z",
     "shell.execute_reply": "2024-04-16T11:37:06.662815Z",
     "shell.execute_reply.started": "2024-04-16T11:37:05.699508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mIndicTransTokenizer\u001b[0m/           LICENSE    requirements.txt\n",
      "\u001b[01;34mIndicTransTokenizer.egg-info\u001b[0m/  README.md  setup.py\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T05:25:56.161364Z",
     "iopub.status.busy": "2024-04-16T05:25:56.160986Z",
     "iopub.status.idle": "2024-04-16T05:25:56.226857Z",
     "shell.execute_reply": "2024-04-16T05:25:56.225919Z",
     "shell.execute_reply.started": "2024-04-16T05:25:56.161330Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read Data from file\n",
    "# Open the first file\n",
    "with open('/kaggle/input/file-dataset/test.en', 'r') as f:\n",
    "    en_dataset = f.readlines()\n",
    "\n",
    "# Open the second file\n",
    "with open('/kaggle/input/file-dataset/test.gu', 'r') as guj_dataset_2:\n",
    "    guj_dataset = guj_dataset_2.readlines()\n",
    "\n",
    "# Open the third file\n",
    "with open('/kaggle/input/file-dataset/test.hi', 'r') as hin_dataset_3:\n",
    "    hin_dataset = hin_dataset_3.readlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the 1000 random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:37:06.666629Z",
     "iopub.status.busy": "2024-04-16T11:37:06.666302Z",
     "iopub.status.idle": "2024-04-16T11:37:06.743563Z",
     "shell.execute_reply": "2024-04-16T11:37:06.742670Z",
     "shell.execute_reply.started": "2024-04-16T11:37:06.666600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: India has a robust strategic partnership with all the three countries.\n",
      "Hindi: भारत के इन सभी तीन देशों के साथ मजबूत रणनीतिक रिश्ते रहे हैं.’\n",
      "Gujarati: આ તમામ ત્રણેય દેશો સાથે ભારતની મજબુત વ્યુહાત્મક ભાગીદારી છે.\n"
     ]
    }
   ],
   "source": [
    "# Load These sentences\n",
    "def load_sentences(file_path):\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            sentences.append(line.strip())  # Remove leading/trailing whitespace\n",
    "    return sentences\n",
    "\n",
    "# Load English sentences\n",
    "en_sentences = load_sentences('/kaggle/input/dataset-2/distilled_english_sentences.txt')\n",
    "\n",
    "# Load Hindi sentences\n",
    "hi_sentences = load_sentences('/kaggle/input/dataset-2/distilled_hindi_sentences.txt')\n",
    "\n",
    "# Load Gujarati sentences\n",
    "gu_sentences = load_sentences('/kaggle/input/dataset-2/distilled_gujarati_sentences.txt')\n",
    "\n",
    "# Print a sentence from each language as an example\n",
    "print(\"English:\", en_sentences[1])\n",
    "print(\"Hindi:\", hi_sentences[1])\n",
    "print(\"Gujarati:\", gu_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:37:06.744907Z",
     "iopub.status.busy": "2024-04-16T11:37:06.744633Z",
     "iopub.status.idle": "2024-04-16T11:37:06.752691Z",
     "shell.execute_reply": "2024-04-16T11:37:06.751684Z",
     "shell.execute_reply.started": "2024-04-16T11:37:06.744883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Translate Function which will convert src to target\n",
    "BATCH_SIZE = 4\n",
    "def translate(model,ip,tokenizer,src,target,input_sentences):\n",
    "    translation = []\n",
    "    for i in range(0,len(input_sentences),BATCH_SIZE):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "        \n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src, tgt_lang=target)\n",
    "        \n",
    "        # Tokenize the batch and generate input encodings\n",
    "        batch = tokenizer(batch, src=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = model.generate(**batch,use_cache=True, num_beams=5, num_return_sequences=1, max_length=256)\n",
    "\n",
    "        # Decode the generated tokens into text\n",
    "        outputs = tokenizer.batch_decode(outputs, src=False)\n",
    "    \n",
    "        # Postprocess the translations, including entity replacement\n",
    "        outputs = ip.postprocess_batch(outputs, lang=target)\n",
    "        translation.append(outputs)\n",
    "        del batch\n",
    "        torch.cuda.empty_cache()\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:37:06.754149Z",
     "iopub.status.busy": "2024-04-16T11:37:06.753880Z",
     "iopub.status.idle": "2024-04-16T11:37:06.767761Z",
     "shell.execute_reply": "2024-04-16T11:37:06.766791Z",
     "shell.execute_reply.started": "2024-04-16T11:37:06.754126Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_code = 'eng_Latn'\n",
    "hin_code =  'hin_Deva'\n",
    "guj_code = 'guj_Gujr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T05:44:19.128900Z",
     "iopub.status.busy": "2024-04-16T05:44:19.128189Z",
     "iopub.status.idle": "2024-04-16T05:44:20.460229Z",
     "shell.execute_reply": "2024-04-16T05:44:20.459316Z",
     "shell.execute_reply.started": "2024-04-16T05:44:19.128867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndicTransForConditionalGeneration(\n",
       "  (model): IndicTransModel(\n",
       "    (encoder): IndicTransEncoder(\n",
       "      (embed_tokens): Embedding(32322, 512, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransEncoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): IndicTransDecoder(\n",
       "      (embed_tokens): Embedding(122672, 512, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransDecoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=122672, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Model and Tokenizer for en-indic\n",
    "tokenizer = IndicTransTokenizer(direction=\"en-indic\")\n",
    "ip = IndicProcessor(inference=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-en-indic-dist-200M\", trust_remote_code=True,low_cpu_mem_usage=True)\n",
    "\n",
    "device=torch.device('cuda',0)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T05:51:00.077392Z",
     "iopub.status.busy": "2024-04-16T05:51:00.076667Z",
     "iopub.status.idle": "2024-04-16T05:53:50.325241Z",
     "shell.execute_reply": "2024-04-16T05:53:50.324338Z",
     "shell.execute_reply.started": "2024-04-16T05:51:00.077357Z"
    }
   },
   "outputs": [],
   "source": [
    "indictrans_en_hi = translate(model,ip,tokenizer,eng_code,hin_code,en_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T06:18:32.071686Z",
     "iopub.status.busy": "2024-04-16T06:18:32.071021Z",
     "iopub.status.idle": "2024-04-16T06:18:32.076907Z",
     "shell.execute_reply": "2024-04-16T06:18:32.075954Z",
     "shell.execute_reply.started": "2024-04-16T06:18:32.071647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर्नाटक में, विशेष रूप से दूर-दराज के स्थानों में, हजारों महिलाओं ने उनकी सेवाओं का लाभ उठाया।\n"
     ]
    }
   ],
   "source": [
    "# Flatten list \n",
    "indictrans_en_hi_corrected = [sentence for sublist in indictrans_en_hi for sentence in sublist]\n",
    "print(indictrans_en_hi_corrected[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T06:30:32.952777Z",
     "iopub.status.busy": "2024-04-16T06:30:32.952154Z",
     "iopub.status.idle": "2024-04-16T06:30:32.962957Z",
     "shell.execute_reply": "2024-04-16T06:30:32.961961Z",
     "shell.execute_reply.started": "2024-04-16T06:30:32.952743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/indictrans_translated_en_hi.zip' target='_blank'>/kaggle/working/indictrans_translated_en_hi.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/indictrans_translated_en_hi.zip"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "from IPython.display import FileLink\n",
    "import os\n",
    "# Save output to a file\n",
    "output_file = \"indictrans_translated_en_hi.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(indictrans_en_hi_corrected))\n",
    "# \n",
    "\n",
    "# Zip the file into the Kaggle output directory\n",
    "zip_file = os.path.join(kaggle_output_dir, \"indictrans_translated_en_hi.zip\")\n",
    "with zipfile.ZipFile(zip_file, 'w') as zipf:\n",
    "    zipf.write(output_file)\n",
    "\n",
    "# Provide a download link to the zip file\n",
    "FileLink(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T06:25:33.873547Z",
     "iopub.status.busy": "2024-04-16T06:25:33.872730Z",
     "iopub.status.idle": "2024-04-16T06:25:34.844659Z",
     "shell.execute_reply": "2024-04-16T06:25:34.843691Z",
     "shell.execute_reply.started": "2024-04-16T06:25:33.873513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndicTransTokenizer\t      indictrans_translated_en_hi.txt\n",
      "IndicTransTokenizer.egg-info  requirements.txt\n",
      "LICENSE\t\t\t      setup.py\n",
      "README.md\t\t      translated_en_hi.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:41:04.701893Z",
     "iopub.status.busy": "2024-04-16T11:41:04.701095Z",
     "iopub.status.idle": "2024-04-16T11:41:13.324357Z",
     "shell.execute_reply": "2024-04-16T11:41:13.323452Z",
     "shell.execute_reply.started": "2024-04-16T11:41:04.701854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5126fc37a8f49d0bf17400d3dfbda6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fb681007dd4a9b92fc739ef06ba59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n",
      "- configuration_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d5bb41af294be9b387525ffd108aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n",
      "- modeling_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf2af581e2c43f38968b7d75745b244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/914M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568f5d0270bd4f33bbae749ad22afaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "IndicTransForConditionalGeneration(\n",
       "  (model): IndicTransModel(\n",
       "    (encoder): IndicTransEncoder(\n",
       "      (embed_tokens): Embedding(122706, 512, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransEncoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): IndicTransDecoder(\n",
       "      (embed_tokens): Embedding(32296, 512, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransDecoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32296, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = IndicTransTokenizer(direction=\"indic-en\")\n",
    "ip = IndicProcessor(inference=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-indic-en-dist-200M\", trust_remote_code=True,low_cpu_mem_usage=True)\n",
    "\n",
    "device=torch.device('cuda',0)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:41:18.919713Z",
     "iopub.status.busy": "2024-04-16T11:41:18.918815Z",
     "iopub.status.idle": "2024-04-16T11:43:52.319280Z",
     "shell.execute_reply": "2024-04-16T11:43:52.318356Z",
     "shell.execute_reply.started": "2024-04-16T11:41:18.919677Z"
    }
   },
   "outputs": [],
   "source": [
    "indictrans_hi_en = translate(model,ip,tokenizer,hin_code,eng_code,hi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:44:14.810910Z",
     "iopub.status.busy": "2024-04-16T11:44:14.810490Z",
     "iopub.status.idle": "2024-04-16T11:44:14.816803Z",
     "shell.execute_reply": "2024-04-16T11:44:14.815785Z",
     "shell.execute_reply.started": "2024-04-16T11:44:14.810878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Flatten list \n",
    "indictrans_hi_en_corrected = [sentence for sublist in indictrans_hi_en for sentence in sublist]\n",
    "print(len(indictrans_hi_en_corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:48:12.010299Z",
     "iopub.status.busy": "2024-04-16T11:48:12.009563Z",
     "iopub.status.idle": "2024-04-16T11:48:12.019178Z",
     "shell.execute_reply": "2024-04-16T11:48:12.018316Z",
     "shell.execute_reply.started": "2024-04-16T11:48:12.010265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/indictrans_translated_hi_en.txt' target='_blank'>/kaggle/working/indictrans_translated_hi_en.txt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/indictrans_translated_hi_en.txt"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "import os\n",
    "# Save output to a file\n",
    "output_file = \"indictrans_translated_hi_en.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(indictrans_hi_en_corrected))\n",
    "\n",
    "# Specify the Kaggle output directory\n",
    "kaggle_output_dir = \"/kaggle/working/\"\n",
    "\n",
    "# Move the file to the Kaggle output directory\n",
    "shutil.move(output_file, os.path.join(kaggle_output_dir, output_file))\n",
    "\n",
    "# Provide a download link to the file\n",
    "FileLink(os.path.join(kaggle_output_dir, output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gujrati to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:52:26.216592Z",
     "iopub.status.busy": "2024-04-16T11:52:26.215826Z",
     "iopub.status.idle": "2024-04-16T11:52:35.262098Z",
     "shell.execute_reply": "2024-04-16T11:52:35.261101Z",
     "shell.execute_reply.started": "2024-04-16T11:52:26.216550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff2a1a1ccab4b4cbd862af63ae0f7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf600b25671a4366b978b63e3224bfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n",
      "- configuration_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba915722d9e940eb9bcf49087a403012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n",
      "- modeling_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf0effb7be84aa1a9068bc861d78f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c3521780804750bc7c04eb92f3e96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "IndicTransForConditionalGeneration(\n",
       "  (model): IndicTransModel(\n",
       "    (encoder): IndicTransEncoder(\n",
       "      (embed_tokens): Embedding(122706, 512, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransEncoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): IndicTransDecoder(\n",
       "      (embed_tokens): Embedding(122672, 512, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransDecoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=122672, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = IndicTransTokenizer(direction=\"indic-indic\")\n",
    "ip = IndicProcessor(inference=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-indic-indic-dist-320M\", trust_remote_code=True,low_cpu_mem_usage=True)\n",
    "\n",
    "device=torch.device('cuda',0)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:53:08.919304Z",
     "iopub.status.busy": "2024-04-16T11:53:08.918925Z",
     "iopub.status.idle": "2024-04-16T11:56:01.849848Z",
     "shell.execute_reply": "2024-04-16T11:56:01.848798Z",
     "shell.execute_reply.started": "2024-04-16T11:53:08.919274Z"
    }
   },
   "outputs": [],
   "source": [
    "indictrans_gu_hi = translate(model,ip,tokenizer,guj_code,hin_code,gu_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:56:01.852046Z",
     "iopub.status.busy": "2024-04-16T11:56:01.851747Z",
     "iopub.status.idle": "2024-04-16T11:56:01.857317Z",
     "shell.execute_reply": "2024-04-16T11:56:01.856403Z",
     "shell.execute_reply.started": "2024-04-16T11:56:01.852020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "इन तीनों देशों के साथ भारत की मजबूत रणनीतिक साझेदारी है।\n"
     ]
    }
   ],
   "source": [
    "# Flatten list \n",
    "indictrans_gu_hi_corrected = [sentence for sublist in indictrans_gu_hi for sentence in sublist]\n",
    "print(indictrans_gu_hi_corrected[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:56:01.858908Z",
     "iopub.status.busy": "2024-04-16T11:56:01.858569Z",
     "iopub.status.idle": "2024-04-16T11:56:01.875498Z",
     "shell.execute_reply": "2024-04-16T11:56:01.874626Z",
     "shell.execute_reply.started": "2024-04-16T11:56:01.858876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/indictrans_translated_gu_hi.zip' target='_blank'>/kaggle/working/indictrans_translated_gu_hi.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/indictrans_translated_gu_hi.zip"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "from IPython.display import FileLink\n",
    "import os\n",
    "# Save output to a file\n",
    "output_file = \"indictrans_translated_gu_hi.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(indictrans_gu_hi_corrected))\n",
    "# \n",
    "\n",
    "# Zip the file into the Kaggle output directory\n",
    "zip_file = os.path.join(kaggle_output_dir, \"indictrans_translated_gu_hi.zip\")\n",
    "with zipfile.ZipFile(zip_file, 'w') as zipf:\n",
    "    zipf.write(output_file)\n",
    "\n",
    "# Provide a download link to the zip file\n",
    "FileLink(zip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi to Gujrati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:56:49.007793Z",
     "iopub.status.busy": "2024-04-16T11:56:49.007074Z",
     "iopub.status.idle": "2024-04-16T11:56:50.776344Z",
     "shell.execute_reply": "2024-04-16T11:56:50.775255Z",
     "shell.execute_reply.started": "2024-04-16T11:56:49.007759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndicTransForConditionalGeneration(\n",
       "  (model): IndicTransModel(\n",
       "    (encoder): IndicTransEncoder(\n",
       "      (embed_tokens): Embedding(122706, 512, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransEncoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): IndicTransDecoder(\n",
       "      (embed_tokens): Embedding(122672, 512, padding_idx=1)\n",
       "      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-17): 18 x IndicTransDecoderLayer(\n",
       "          (self_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): IndicTransAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=122672, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = IndicTransTokenizer(direction=\"indic-indic\")\n",
    "ip = IndicProcessor(inference=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-indic-indic-dist-320M\", trust_remote_code=True,low_cpu_mem_usage=True)\n",
    "\n",
    "device=torch.device('cuda',0)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:56:50.778193Z",
     "iopub.status.busy": "2024-04-16T11:56:50.777899Z",
     "iopub.status.idle": "2024-04-16T11:59:38.995353Z",
     "shell.execute_reply": "2024-04-16T11:59:38.994487Z",
     "shell.execute_reply.started": "2024-04-16T11:56:50.778168Z"
    }
   },
   "outputs": [],
   "source": [
    "indictrans_hi_gu = translate(model,ip,tokenizer,hin_code,guj_code,hi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:59:38.996940Z",
     "iopub.status.busy": "2024-04-16T11:59:38.996648Z",
     "iopub.status.idle": "2024-04-16T11:59:39.002368Z",
     "shell.execute_reply": "2024-04-16T11:59:39.001461Z",
     "shell.execute_reply.started": "2024-04-16T11:59:38.996915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "આ ત્રણેય દેશો સાથે ભારતના મજબૂત વ્યૂહાત્મક સંબંધો છે.\n"
     ]
    }
   ],
   "source": [
    "# Flatten list \n",
    "indictrans_hi_gu_corrected = [sentence for sublist in indictrans_hi_gu for sentence in sublist]\n",
    "print(indictrans_hi_gu_corrected[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T11:59:39.004380Z",
     "iopub.status.busy": "2024-04-16T11:59:39.004115Z",
     "iopub.status.idle": "2024-04-16T11:59:39.024280Z",
     "shell.execute_reply": "2024-04-16T11:59:39.023403Z",
     "shell.execute_reply.started": "2024-04-16T11:59:39.004357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/indictrans_translated_hi_gu.zip' target='_blank'>/kaggle/working/indictrans_translated_hi_gu.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/indictrans_translated_hi_gu.zip"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "from IPython.display import FileLink\n",
    "import os\n",
    "# Save output to a file\n",
    "output_file = \"indictrans_translated_hi_gu.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(indictrans_hi_gu_corrected))\n",
    "# \n",
    "\n",
    "# Zip the file into the Kaggle output directory\n",
    "zip_file = os.path.join(kaggle_output_dir, \"indictrans_translated_hi_gu.zip\")\n",
    "with zipfile.ZipFile(zip_file, 'w') as zipf:\n",
    "    zipf.write(output_file)\n",
    "\n",
    "# Provide a download link to the zip file\n",
    "FileLink(zip_file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4802019,
     "sourceId": 8125584,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4802250,
     "sourceId": 8125879,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4802347,
     "sourceId": 8126009,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4810024,
     "sourceId": 8136590,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
